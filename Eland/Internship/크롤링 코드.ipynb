{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "Options= webdriver.ChromeOptions()\n",
    "user_agent= \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\"\n",
    "Options.add_argument('user-agent=' + user_agent)\n",
    "# Options.add_argument(\"headless\")\n",
    "\n",
    "\n",
    "# get_prices() : 네이버 가격비교에서 크롤링하는 함수\n",
    "    # product_cd : 상품코드\n",
    "    # product_name : 상품명\n",
    "    # o_price : 정가\n",
    "def get_prices(product_cd,product_name,o_price):\n",
    "\n",
    "    # 1. 네이버 쇼핑에서 상품코드를 검색한 페이지로 접속한 후, 가격비교 페이지 링크/상품 가격링크 가져오는 과정\n",
    "    response=requests.get(\"https://search.shopping.naver.com/search/all?query={}\".format(product_cd))\n",
    "    search_page_html=response.text\n",
    "    search_page_soup=BeautifulSoup(search_page_html,'html.parser')\n",
    "    try:\n",
    "        search_page_contents_count=min(len(search_page_soup.select('#content > div.style_content__xWg5l > div.basicList_list_basis__uNBZx > div')[0]),5)\n",
    "        \n",
    "        # 해당 상품의 가격비교 url을 담을 리스트\n",
    "        product_urls=[]\n",
    "        \n",
    "        # 해당상품 검색 페이지에 있는 판매 리스트 중, 해외상품을 제외하고, 가격비교 링크/가격비교가 아니지만 검색된 스파오 상품을 추려냅니다.\n",
    "        # 가격비교 링크의 경우 product_urls에 저장한 후, Selenium으로 접근해 동적 크롤링을 진행하고,\n",
    "        # 검색결과 가격비교 없이, 첫 번째 검색결과가 스파오 판매글일 경우, 지금 바로 해당 가격정보 및 결과를 리턴합니다\n",
    "        for i in range(1,search_page_contents_count+1):\n",
    "            content_details=search_page_soup.select('#content > div.style_content__xWg5l > div.basicList_list_basis__uNBZx > div > div:nth-child({}) > div'.format(i))[0]\n",
    "            if \"해외\" not in content_details.get_text() :\n",
    "                if '쇼핑몰별 최저가' in content_details.get_text() :\n",
    "                    product_url = content_details.select('#content > div.style_content__xWg5l > div.basicList_list_basis__uNBZx > div > div:nth-child({}) > div > div > div.product_info_area__xxCTi > div.product_title__Mmw2K > a'.format(i))[0]['href']\n",
    "                    product_urls.append(product_url)\n",
    "                else:\n",
    "                    check_list=['스파오','SPAO','spao','Spao']\n",
    "                    for value in check_list:\n",
    "                        if i==1 and value in content_details.get_text():\n",
    "                            seller=search_page_soup.select('#content > div.style_content__xWg5l > div.basicList_list_basis__uNBZx > div > div > div > div')[0]\n",
    "                            if not seller :\n",
    "                                seller = search_page_soup.select('#content > div.style_content__xWg5l > div.basicList_list_basis__uNBZx > div > div > div > div > div.product_mall_area___f3wo > div.product_mall_title__Xer1m > a.product_mall__hPiEH.linkAnchor > img')[0]['alt']\n",
    "                            price=search_page_soup.select('#content > div.style_content__xWg5l > div.basicList_list_basis__uNBZx > div > div > div > div > div.product_info_area__xxCTi > div.product_price_area__eTg7I > strong > span.price_price__LEGN7 > span')[0].get_text()\n",
    "                            price=int(price.replace(',','')[:-1])\n",
    "                            s_rate=1-(int(price)/int(o_price))\n",
    "                            d_fee=search_page_soup.select('#content > div.style_content__xWg5l > div.basicList_list_basis__uNBZx > div > div > div > div > div.product_info_area__xxCTi > div.product_price_area__eTg7I > strong > span.price_delivery__yw_We')[0].get_text()\n",
    "                            if \"무료\" in d_fee:\n",
    "                                d_fee = 0\n",
    "                            else :\n",
    "                                d_fee=int(d_fee[3:-1].replace(',',''))\n",
    "                            price=price+d_fee\n",
    "                            \n",
    "                            m_price=price\n",
    "                            t = str(datetime.now())[:10]\n",
    "                            ch_url = search_page_soup.select('#content > div.style_content__xWg5l > div.basicList_list_basis__uNBZx > div > div > div > div > div.product_info_area__xxCTi > div.product_title__Mmw2K > a')[0]['href']\n",
    "                            raw_data={'수집채널': seller,'상품코드' : product_cd,'상품명':product_name,'정상가':o_price,'노출가':price,'할인율':s_rate,'배송비':d_fee,'최저가(쿠폰적용)':m_price,'수집시점':t,'링크':ch_url}\n",
    "                            data= pd.Series(raw_data)\n",
    "                            return data                \n",
    "            else :\n",
    "                print(\"해외상품임\")\n",
    "            \n",
    "        # 모아온 해당상품의 가격비교 링크를 바탕으로 아래의 작업을 수행합니다.\n",
    "        if product_urls !=[]:\n",
    "            sellers=[]      # 수집 채널\n",
    "            codes=[]        # 상품코드\n",
    "            names=[]        # 상품명\n",
    "            o_prices=[]     # 정상가\n",
    "            prices=[]       # 노출가\n",
    "            s_rate=[]       # 할인율\n",
    "            d_fees=[]       # 배송비\n",
    "            m_prices=[]     # 최저가\n",
    "            times=[]        # 수집 시점\n",
    "            ch_urls=[]      # 판매 채널별 url 수집\n",
    "\n",
    "            # 해당 상품의 상품비교 url을 차례로 방문합니다.(Selenium)\n",
    "            for product_url in product_urls:\n",
    "                driver = webdriver.Chrome(options=Options)\n",
    "                driver.get(product_url)\n",
    "                # 만약 상세페이지에 아무것도 없다면(네이버 서버문제), 예외처리 수행\n",
    "                try : \n",
    "                    # 배송비 및 카드할인 포함 클릭\n",
    "                    driver.find_element_by_xpath(\"//*[@id=\\\"content\\\"]/div[1]/div/div[2]/div[2]/div/div/div[1]/div[2]/div[1]/a\").click()\n",
    "                    time.sleep(1)\n",
    "                    driver.find_element_by_xpath(\"//*[@id=\\\"content\\\"]/div[1]/div/div[2]/div[2]/div/div/div[1]/div[2]/div[2]/a\").click()\n",
    "                    time.sleep(1)\n",
    "\n",
    "                    # 스크롤 내리기\n",
    "                    driver.execute_script(\"window.scrollTo(0, 1000)\")\n",
    "                    time.sleep(1)\n",
    "                    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "                    time.sleep(3)\n",
    "                    \n",
    "                    # page_length : 가격비교 링크에서 넘겨야할 총 페이지 개수\n",
    "                    first_page_html = driver.page_source\n",
    "                    first_page_soup=BeautifulSoup(first_page_html, 'html.parser')\n",
    "                    if first_page_soup.select('#section_price > div.productList_seller_wrap__FZtUS > div.pagination_pagination__JW7zT') :\n",
    "                        page_length=len(first_page_soup.select('#section_price > div.productList_seller_wrap__FZtUS > div.pagination_pagination__JW7zT')[0])\n",
    "                    else:\n",
    "                        page_length=1\n",
    "\n",
    "                    # 각 페이지를 방문하며 가격정보를 가져옵니다.\n",
    "                    for page in range(1,page_length+1):\n",
    "                        if page==1:\n",
    "                            pass\n",
    "                        else:\n",
    "                            driver.find_element_by_xpath(\"/html/body/div/div/div[2]/div[2]/div[2]/div[3]/div[3]/div[3]/div[2]/a[{}]\".format(page)).send_keys(Keys.ENTER)\n",
    "                            time.sleep(2)\n",
    "\n",
    "                        # 페이지에 출력된 모든 가격정보를 받아옵니다.\n",
    "                        html = driver.page_source\n",
    "                        soup=BeautifulSoup(html, 'html.parser')\n",
    "                        content=soup.select('#section_price > div.productList_seller_wrap__FZtUS > ul')[0]\n",
    "\n",
    "                        for i in range(1,len(content)+1):\n",
    "                            # 만약 상품코드가 딜러의 상품명에 명확히 없다면 다음 가격정보를 받아옵니다.\n",
    "                            # 가격비교 페이지 안에도, 다른 상품코드의 상품이 혼재되어있는 경우가 있습니다.\n",
    "                            # 이 경우, 전혀 다른 상품이기 때문에 잘못된 가격정보수집을 막기위해 아래의 작업을 수행합니다.\n",
    "                            n=content.select('#section_price > div.productList_seller_wrap__FZtUS > ul > li:nth-child({}) > div > div.productList_product__b2cSY > a'.format(i))[0].get_text()\n",
    "                            if product_cd not in n:\n",
    "                                continue\n",
    "\n",
    "                            img = content.select('#section_price > div.productList_seller_wrap__FZtUS > ul > li:nth-child({}) > div > div.productList_mall__JtWmC > a > img'.format(i))\n",
    "                            if img != []:\n",
    "                                seller=img[0]['alt']\n",
    "                            else:\n",
    "                                seller=content.select('#section_price > div.productList_seller_wrap__FZtUS > ul > li:nth-child({}) > div > div.productList_mall__JtWmC > a > span:nth-child(1)'.format(i))[0].get_text()\n",
    "\n",
    "                            price=content.select('#section_price > div.productList_seller_wrap__FZtUS > ul > li:nth-child({}) > div > div.productList_price__2eGt4 > a > span > em'.format(i))[0].get_text().replace(',','')\n",
    "\n",
    "                            d_fee=content.select('#section_price > div.productList_seller_wrap__FZtUS > ul > li:nth-child({}) > div > div.productList_price__2eGt4 > div'.format(i))[0].get_text()\n",
    "                            if d_fee==\"무료배송\":\n",
    "                                d_fee=0\n",
    "                            else :\n",
    "                                d_fee=d_fee.replace(',','')\n",
    "                                d_fee=int(d_fee[:4])\n",
    "\n",
    "                            ch_url = content.select('#section_price > div.productList_seller_wrap__FZtUS > ul > li:nth-child({}) > div > div.productList_product__b2cSY > a'.format(i))[0]['href']\n",
    "\n",
    "                            sellers.append(seller)\n",
    "                            codes.append(product_cd)\n",
    "                            names.append(product_name)\n",
    "                            o_prices.append(int(o_price))\n",
    "                            prices.append(int(price))\n",
    "                            s_rate.append(1-(int(price)/int(o_price)))\n",
    "                            d_fees.append(int(d_fee))\n",
    "                            times.append(str(datetime.now())[:10])\n",
    "                            m_prices.append(min(prices))\n",
    "                            ch_urls.append(ch_url)\n",
    "\n",
    "\n",
    "                # 막상 가격비교 링크에 접속하니 가격정보가 아예 안뜨는 경우가 있습니다.\n",
    "                # 이 경우, 오류를 출력하며 크롤링이 중단되는 상황을 막기위해, 예외처리를 수행합니다.\n",
    "                # 그리고, 정말로 해당 페이지에 오류가 있어 가져오지 못하는 것인지 모든 크롤링을 마친 후 직접 확인하고자, 해당 링크정보를 출력합니다.\n",
    "                except NoSuchElementException:\n",
    "                    print(\"네이버 서버 오류로 인해, 해당 url은 수집하지 않습니다.\")\n",
    "                    print(\"==>{}\".format(product_url))\n",
    "                    continue\n",
    "\n",
    "            # 받아온 데이터 수집 및 데이터프레임으로 정리하여 리턴합니다.\n",
    "            raw_data={'수집채널': sellers,'상품코드' : codes,'상품명':names,'정상가':o_prices,'노출가':prices,'할인율':s_rate,'배송비':d_fees,'최저가(쿠폰적용)':m_prices,'수집시점':times, '링크':ch_urls}\n",
    "            data= pd.DataFrame(raw_data)\n",
    "            return data\n",
    "\n",
    "    #만약 판매자가 아예 없는 경우(검색결과가 없는 경우), 아래와 같이 리턴합니다.\n",
    "    except IndexError:\n",
    "        t = str(datetime.now())[:10]\n",
    "        raw_data={'수집채널': '가격비교 없음','상품코드' : product_cd,'상품명':product_name,'정상가':o_price,'노출가':-1,'할인율':0,'배송비':0,'최저가(쿠폰적용)':-1,'수집시점':t, '링크':'링크 없음'}\n",
    "        data= pd.Series(raw_data)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스파오 닷컴 크롤링\n",
    "def get_spao_com_price(product_cd, product_name,o_price):\n",
    "\n",
    "    ch_url='https://www.spao.com/product/search.html?banner_action=&sort_method=5&except_keyword=except&keyword={}'.format(product_cd)\n",
    "    # 그냥 하면 403오류가 발생하므로, user-agent를 설정합니다.\n",
    "    response=requests.get(ch_url,headers={\"User-Agent\" : \"Mozilla/5.0\"})\n",
    "    html=response.text\n",
    "    soup=BeautifulSoup(html,'html.parser')\n",
    "    \n",
    "    # 배송비 포함하지 않은 노출가\n",
    "    prices_html = soup.select('div > div.description > div.price_box > span.price')\n",
    "    # 결과물 담을 리스트\n",
    "    sellers=[]      # 수집 채널\n",
    "    codes=[]        # 상품코드\n",
    "    names=[]        # 상품명\n",
    "    o_prices=[]     # 정상가\n",
    "    prices=[]       # 노출가\n",
    "    s_rate=[]       # 할인율\n",
    "    d_fees=[]       # 배송비\n",
    "    m_prices=[]     # 최저가\n",
    "    times=[]        # 수집 시점\n",
    "    ch_urls=[]      # 판매 채널별 url 수집\n",
    "\n",
    "    for i in range(len(prices_html)):\n",
    "        price=int(prices_html[i].get_text().replace(',',''))\n",
    "        prices.append(price)\n",
    "\n",
    "    prices=list(set(prices))\n",
    "    \n",
    "    prices_list=prices.copy()\n",
    "    for p in prices_list:\n",
    "        sellers.append('스파오닷컴')\n",
    "        codes.append(product_cd)\n",
    "        names.append(product_name)\n",
    "        o_prices.append(o_price)\n",
    "        times.append(str(datetime.now())[:10])\n",
    "        ch_urls.append(ch_url)\n",
    "        if price>=30000:\n",
    "            d_fee=0\n",
    "        else:\n",
    "            d_fee=2500\n",
    "        d_fees.append(d_fee)\n",
    "\n",
    "        # 판매가 + 배송비로 노출가를 업데이트\n",
    "        price = p+d_fee\n",
    "        m_prices.append(min(prices))\n",
    "        s_rate.append(1-(int(price)/int(o_price)))\n",
    "\n",
    "        \n",
    "\n",
    "    ch_url=\"https://www.spao.com/product/search.html?banner_action=&sort_method=5&except_keyword=except&keyword={}\".format(product_cd)\n",
    "\n",
    "    if prices:\n",
    "        spao_data={'수집채널': sellers,'상품코드' : codes,'상품명':names,'정상가':o_prices,'노출가':prices,'할인율':s_rate,'배송비':d_fees,'최저가(쿠폰적용)': m_prices,'수집시점':times, '링크':ch_urls}\n",
    "        spao_data=pd.DataFrame(spao_data)\n",
    "        return spao_data    \n",
    "    else:\n",
    "        print(\"스파오 닷컴엔 해당 상품이 없습니다.\")\n",
    "        return\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_list=pd.read_excel('./data/크롤링상품리스트.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data=pd.DataFrame(columns=['수집채널','상품코드','상품명','정상가','노출가','할인율','배송비','최저가(쿠폰적용)','수집시점','링크'])\n",
    "count=1\n",
    "errors={}\n",
    "\n",
    "for idx, product_info in p_list.iterrows():\n",
    "\n",
    "    product_cd=product_info[1]\n",
    "    product_name=product_info[2]\n",
    "    o_price=product_info[3]\n",
    "    try:\n",
    "        spao_data=get_spao_com_price(product_cd,product_name,o_price)\n",
    "        data=get_prices(product_cd,product_name,o_price)\n",
    "\n",
    "        # 스파오닷컴과 가격비교 데이터 모두 비어있지 않다면 수행하는 작업입니다.\n",
    "        if spao_data is not None and data is not None :\n",
    "            # 스파오 닷컴과 가격비교 크롤링 df를 합치고, 최저가를 새로 계산해 덮어씌웁니다.\n",
    "            concat_data = spao_data.append(data, ignore_index=True)\n",
    "            concat_data['최저가(쿠폰적용)']=min(concat_data['노출가'])\n",
    "            count +=1\n",
    "            final_data=final_data.append(concat_data,ignore_index=True)\n",
    "        \n",
    "        # 스파오닷컴 or 가격비교 크롤링 df 둘 중 하나만있다면 있는 것에 대해서만 작업을 수행합니다.\n",
    "        elif spao_data is None and data is not None:\n",
    "            final_data=final_data.append(data)\n",
    "        elif spao_data is not None and data is None:\n",
    "            final_data=final_data.append(spao_data)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(product_info[1],\"에서 문제가 발생했네요\\n\",e)\n",
    "        \n",
    "        # 에러가 발생하면, 혹시 모르니, 해당 지점에서 현재까지 모아둔 데이터를 저장해둡니다.\n",
    "        final_data.to_csv('./errors/data_{}(중단 지점).csv'.format(idx),encoding='utf-8')\n",
    "\n",
    "        # 에러가 발생하면, 에러가 발생한 상품코드와 에러코드를 기록해두는 딕셔너리입니다.\n",
    "        errors[product_cd]=e\n",
    "        count +=1\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 크롤링 과정에서 발생한 에러를 확인합니다.\n",
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링 데이터를 서버로 전송하는 과정\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "engine = create_engine('postgresql+psycopg2://test:1234@44.210.40.11/test_db')\n",
    "# DataFrame을 DB로 전송합니다.\n",
    "table_name = 'cr_data'  # 병합할 PostgreSQL 테이블명\n",
    "final_data.to_sql(name=table_name, con=engine, if_exists='append', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Eland_project_3_8_16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
