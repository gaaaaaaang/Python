{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0nJf_J5Yqhmf"
   },
   "outputs": [],
   "source": [
    "# This mounts your Google Drive to the Colab VM.\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive', force_remount=True)\n",
    "DATA_PATH = \"/Users/hyunwoo/Downloads/Jobcare_data\"\n",
    "SUBMIT_PATH = '/Users/hyunwoo/Downloads/Jobcare_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gFCqs8CRav_V"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3I1oT32kqper"
   },
   "outputs": [],
   "source": [
    "# install tabnet\n",
    "!pip install pytorch_tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Light_Famd in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (0.0.3)\r\n",
      "Requirement already satisfied: scikit-learn in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from Light_Famd) (0.23.2)\r\n",
      "Requirement already satisfied: numpy in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from Light_Famd) (1.21.4)\r\n",
      "Requirement already satisfied: scipy in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from Light_Famd) (1.5.2)\r\n",
      "Requirement already satisfied: pandas in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from Light_Famd) (1.3.5)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->Light_Famd) (2.1.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->Light_Famd) (0.17.0)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from pandas->Light_Famd) (2020.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from pandas->Light_Famd) (2.8.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->Light_Famd) (1.16.0)\r\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Light_Famd'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-46c0e768805d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install Light_Famd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mLight_Famd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Light_Famd'"
     ]
    }
   ],
   "source": [
    "!pip install Light_Famd\n",
    "from Light_Famd import CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "GZOF5VWaqrsw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: prince in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (0.7.1)\n",
      "Requirement already satisfied: numpy>=1.17.1 in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from prince) (1.21.4)\n",
      "Requirement already satisfied: scikit-learn>=0.22.1 in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from prince) (0.23.2)\n",
      "Requirement already satisfied: scipy>=1.3.0 in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from prince) (1.5.2)\n",
      "Requirement already satisfied: matplotlib>=3.0.2 in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from prince) (3.3.2)\n",
      "Requirement already satisfied: pandas>=1.0.3 in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from prince) (1.3.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.22.1->prince) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.22.1->prince) (0.17.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from matplotlib>=3.0.2->prince) (2020.6.20)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from matplotlib>=3.0.2->prince) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from matplotlib>=3.0.2->prince) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from matplotlib>=3.0.2->prince) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from matplotlib>=3.0.2->prince) (1.3.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from matplotlib>=3.0.2->prince) (8.0.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from pandas>=1.0.3->prince) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.1->matplotlib>=3.0.2->prince) (1.16.0)\n",
      "Requirement already satisfied: catboost in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (1.0.4)\n",
      "Requirement already satisfied: matplotlib in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from catboost) (3.3.2)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from catboost) (1.3.5)\n",
      "Requirement already satisfied: six in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from catboost) (1.21.4)\n",
      "Requirement already satisfied: scipy in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from catboost) (1.5.2)\n",
      "Requirement already satisfied: plotly in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from catboost) (5.5.0)\n",
      "Requirement already satisfied: graphviz in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from catboost) (0.19.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->catboost) (1.3.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->catboost) (8.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->catboost) (2020.6.20)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->catboost) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->catboost) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from pandas>=0.24.0->catboost) (2020.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from plotly->catboost) (8.0.1)\n",
      "Requirement already satisfied: bayesian-optimization in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (1.2.0)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from bayesian-optimization) (1.5.2)\n",
      "Requirement already satisfied: scikit-learn>=0.18.0 in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from bayesian-optimization) (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from bayesian-optimization) (1.21.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/hyunwoo/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install prince\n",
    "import prince\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "from pytorch_tabnet.metrics import Metric \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 라이브러리 설치\n",
    "import warnings                                      # 경고 메세지 무시\n",
    "warnings.filterwarnings('ignore')\n",
    "import random                                        # 난수 생성\n",
    "random.seed(2020)\n",
    "random_seed = 2020\n",
    "import time                                          # 시간 측정\n",
    "import re                                            # 정규표현식\n",
    "\n",
    "from sklearn.model_selection import train_test_split # train, validation 데이터 나누기\n",
    "from sklearn import metrics                          # AUC 측정\n",
    "!pip install catboost\n",
    "from catboost import CatBoostClassifier, Pool        # CatBoost 모델링\n",
    "from sklearn.model_selection import KFold            # K-fold CV    \n",
    "!pip install bayesian-optimization\n",
    "from bayes_opt import BayesianOptimization           # 베이지안 최적화 라이브러리  \n",
    "from functools import partial                        # 함수 변수 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "id": "2JPFJsP7qtDZ"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(DATA_PATH + '/train.csv')\n",
    "df_test  = pd.read_csv(DATA_PATH + '/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "id": "8Y25B87VqvFV"
   },
   "outputs": [],
   "source": [
    "d_code = pd.read_csv(DATA_PATH + '/att_D.csv', index_col=0).T.to_dict()\n",
    "h_code = pd.read_csv(DATA_PATH + '/att_H.csv', index_col=0).T.to_dict()\n",
    "l_code = pd.read_csv(DATA_PATH + '/att_L.csv', index_col=0).T.to_dict()\n",
    "\n",
    "def add_code(\n",
    "    df: pd.DataFrame,\n",
    "    d_code: Dict[int, Dict[str, int]], \n",
    "    h_code: Dict[int, Dict[str, int]], \n",
    "    l_code: Dict[int, Dict[str, int]],\n",
    ") -> pd.DataFrame:\n",
    "    \n",
    "    # Copy input data\n",
    "    df = df.copy()   \n",
    "\n",
    "    # D Code\n",
    "    df['person_prefer_d_1_n'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
    "    df['person_prefer_d_1_s'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
    "    df['person_prefer_d_1_m'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
    "    df['person_prefer_d_1_l'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
    "\n",
    "    df['person_prefer_d_2_n'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
    "    df['person_prefer_d_2_s'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
    "    df['person_prefer_d_2_m'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
    "    df['person_prefer_d_2_l'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
    "\n",
    "    df['person_prefer_d_3_n'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
    "    df['person_prefer_d_3_s'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
    "    df['person_prefer_d_3_m'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
    "    df['person_prefer_d_3_l'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
    "\n",
    "    df['contents_attribute_d_n'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
    "    df['contents_attribute_d_s'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
    "    df['contents_attribute_d_m'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
    "    df['contents_attribute_d_l'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
    "\n",
    "    # H Code\n",
    "    df['person_prefer_h_1_l'] = df['person_prefer_h_1'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
    "    df['person_prefer_h_1_m'] = df['person_prefer_h_1'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
    "    \n",
    "    df['person_prefer_h_2_l'] = df['person_prefer_h_2'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
    "    df['person_prefer_h_2_m'] = df['person_prefer_h_2'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
    "    \n",
    "    df['person_prefer_h_3_l'] = df['person_prefer_h_3'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
    "    df['person_prefer_h_3_m'] = df['person_prefer_h_3'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
    "\n",
    "    df['contents_attribute_h_l'] = df['contents_attribute_h'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
    "    df['contents_attribute_h_m'] = df['contents_attribute_h'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
    "\n",
    "    # L Code\n",
    "    df['contents_attribute_l_n'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 세분류코드'])\n",
    "    df['contents_attribute_l_s'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 소분류코드'])\n",
    "    df['contents_attribute_l_m'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 중분류코드'])\n",
    "    df['contents_attribute_l_l'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 대분류코드'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_train = add_code(df_train, d_code, h_code, l_code)\n",
    "df_test  = add_code(df_test, d_code, h_code, l_code)\n",
    "# 35에서 63으로 column 개수 증가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "id": "i8YEn3gjfF6-"
   },
   "outputs": [],
   "source": [
    "\n",
    "contentsrn = df_train['contents_rn'].value_counts()\n",
    "contentsrn2 = df_test['contents_rn'].value_counts()\n",
    "ct = df_train['person_rn'].value_counts()\n",
    "ct2 = df_test['person_rn'].value_counts()\n",
    "df_train['person_count'] = df_train['person_rn'].apply(lambda x: ct[x])\n",
    "df_test['person_count'] = df_test['person_rn'].apply(lambda x: ct2[x])\n",
    "df_train['contents_count'] = df_train['contents_rn'].apply(lambda x: contentsrn[x])\n",
    "df_test['contents_count'] = df_test['contents_rn'].apply(lambda x: contentsrn2[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contents_count</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.402177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.476306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.536793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.588552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.615681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.650326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.666541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.694022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.701925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.716568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.719862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.738971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.723404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.744589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.676596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.707386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.716912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.726190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.605263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.816667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.730435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.821429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.655172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.871795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  target\n",
       "contents_count          \n",
       "1               0.402177\n",
       "2               0.476306\n",
       "3               0.536793\n",
       "4               0.588552\n",
       "5               0.615681\n",
       "6               0.650326\n",
       "7               0.666541\n",
       "8               0.694022\n",
       "9               0.701925\n",
       "10              0.716568\n",
       "11              0.719862\n",
       "12              0.738971\n",
       "13              0.723404\n",
       "14              0.744589\n",
       "15              0.676596\n",
       "16              0.707386\n",
       "17              0.716912\n",
       "18              0.726190\n",
       "19              0.605263\n",
       "20              0.816667\n",
       "21              0.714286\n",
       "22              0.727273\n",
       "23              0.730435\n",
       "24              0.708333\n",
       "28              0.821429\n",
       "29              0.655172\n",
       "32              0.875000\n",
       "36              0.722222\n",
       "39              0.871795"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[:,['contents_count', 'target']].groupby(by=['contents_count']).mean('target')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "id": "K-oUUKFda_lm"
   },
   "outputs": [],
   "source": [
    "df_train['Hour'] = pd.to_datetime(df_train['contents_open_dt']).dt.hour \n",
    "df_train['day'] = pd.to_datetime(df_train['contents_open_dt']).dt.dayofweek\n",
    "df_test['Hour'] = pd.to_datetime(df_test['contents_open_dt']).dt.hour \n",
    "df_test['day']= pd.to_datetime(df_test['contents_open_dt']).dt.dayofweek "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "id": "Q_UI-W1Rqf30"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n##########################/ 09~19 , 19~01 , 01~09  / 0,1,2\\nfor i in range(len(df_train)):\\n  if df_train['Hour'][i] >= 1 and df_train['Hour'][i]<9:\\n    df_train['Hour'][i] = 0\\n  elif df_train['Hour'][i] >=9 and df_train['Hour'][i]<19:\\n    df_train['Hour'][i] = 1\\n  else:\\n    df_train['Hour'][i] = 2 \\n\\nfor i in range(len(df_test)):\\n  if df_test['Hour'][i] >= 1 and df_test['Hour'][i]<9:\\n    df_test['Hour'][i] = 0\\n  elif df_test['Hour'][i] >=9 and df_test['Hour'][i]<19:\\n    df_test['Hour'][i] = 1\\n  else:\\n    df_test['Hour'][i] = 2 \\n    \\n############################################ 월~금=0 , 토~일 = 1 \\nfor i in range(len(df_train)):\\n  if df_train['day'][i] < 5:\\n    df_train['day'][i] = 1\\n  else:\\n    df_train['day'][i] = 0\\n\\nfor i in range(len(df_test)):\\n  if df_test['day'][i] <5:\\n    df_test['day'][i] = 1\\n  else:\\n    df_test['day'][i] = 0\\n\""
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "##########################/ 09~19 , 19~01 , 01~09  / 0,1,2\n",
    "for i in range(len(df_train)):\n",
    "  if df_train['Hour'][i] >= 1 and df_train['Hour'][i]<9:\n",
    "    df_train['Hour'][i] = 0\n",
    "  elif df_train['Hour'][i] >=9 and df_train['Hour'][i]<19:\n",
    "    df_train['Hour'][i] = 1\n",
    "  else:\n",
    "    df_train['Hour'][i] = 2 \n",
    "\n",
    "for i in range(len(df_test)):\n",
    "  if df_test['Hour'][i] >= 1 and df_test['Hour'][i]<9:\n",
    "    df_test['Hour'][i] = 0\n",
    "  elif df_test['Hour'][i] >=9 and df_test['Hour'][i]<19:\n",
    "    df_test['Hour'][i] = 1\n",
    "  else:\n",
    "    df_test['Hour'][i] = 2 \n",
    "    \n",
    "############################################ 월~금=0 , 토~일 = 1 \n",
    "for i in range(len(df_train)):\n",
    "  if df_train['day'][i] < 5:\n",
    "    df_train['day'][i] = 1\n",
    "  else:\n",
    "    df_train['day'][i] = 0\n",
    "\n",
    "for i in range(len(df_test)):\n",
    "  if df_test['day'][i] <5:\n",
    "    df_test['day'][i] = 1\n",
    "  else:\n",
    "    df_test['day'][i] = 0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hour</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.469570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.444165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.441021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.456365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.440096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.452622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.473348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.495428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.523567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.520038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.523644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.522432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.515023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.516241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.518616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.512387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.511428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.497675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.491195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.484552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.482290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.475429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.473592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.462973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        target\n",
       "Hour          \n",
       "0     0.469570\n",
       "1     0.444165\n",
       "2     0.441021\n",
       "3     0.456365\n",
       "4     0.440096\n",
       "5     0.452622\n",
       "6     0.473348\n",
       "7     0.495428\n",
       "8     0.523567\n",
       "9     0.520038\n",
       "10    0.523644\n",
       "11    0.522432\n",
       "12    0.515023\n",
       "13    0.516241\n",
       "14    0.518616\n",
       "15    0.512387\n",
       "16    0.511428\n",
       "17    0.497675\n",
       "18    0.491195\n",
       "19    0.484552\n",
       "20    0.482290\n",
       "21    0.475429\n",
       "22    0.473592\n",
       "23    0.462973"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[:,['Hour', 'target']].groupby(by=['Hour']).mean('target')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "id": "J2zmR2hMtAdg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD4CAYAAADy46FuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAATK0lEQVR4nO3df4ydVX7f8fenkBBnN1B+hJGFaU2KlQawsgkWod0qmsrV4marmkogOSLBVK5cITbdVJYqk3+oWlkCqYSEqiC5hWLodsEl22KV0iwyGaWVWBOzWdULLsIKLnhxcSiE4FUhDPn2j3tGvR7GB3uuPXc8835JV/e53+c55545ejwfPz/m3lQVkiSdzF8Y9wAkSYubQSFJ6jIoJEldBoUkqcugkCR1nT/uAZxpl112Wa1evXre7X/4wx/yhS984cwN6BzlPAw4DwPOw8BSnoeXX3753ar6ybnWLbmgWL16Nfv37593+6mpKSYnJ8/cgM5RzsOA8zDgPAws5XlI8r9Ots5TT5KkLoNCktRlUEiSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpK4l95fZkj5r9fZnR2q/be00d8yzj8P3fnWk99b4eUQhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK6DApJUpdBIUnqMigkSV0GhSSpy6CQJHUZFJKkLoNCktRlUEiSuj43KJI8muRYku8P1S5J8nyS19vzxUPr7k5yKMlrSW4aql+f5EBb92CStPoFSZ5q9X1JVg+12dze4/Ukm8/YTy1JOmWnckTxGLBhVm07sLeq1gB722uSXANsAq5tbR5Kcl5r8zCwFVjTHjN9bgHer6qrgQeA+1pflwD3AL8A3ADcMxxIkqSF8blBUVW/D7w3q7wR2NWWdwE3D9WfrKqPq+oN4BBwQ5KVwIVV9WJVFfD4rDYzfT0NrG9HGzcBz1fVe1X1PvA8nw0sSdJZNt+vQp2oqqMAVXU0yeWtfgXwnaHtjrTaJ215dn2mzVutr+kkHwCXDtfnaHOCJFsZHK0wMTHB1NTUPH8sOH78+EjtlwrnYWCpzMO2tdMjtZ9YMf8+lsL8zVgq+8PpOtPfmZ05atWpz7fNicWqncBOgHXr1tXk5OTnDvRkpqamGKX9UuE8DCyVeZjv913P2LZ2mvsPzO/XxeHbJkd678VkqewPp2u+dz29004n0Z6PtfoR4Mqh7VYBb7f6qjnqJ7RJcj5wEYNTXSfrS5K0gOYbFHuAmbuQNgPPDNU3tTuZrmJw0fqldprqwyQ3tusPt89qM9PXLcAL7TrG7wJfSXJxu4j9lVaTJC2gzz2WTPJNYBK4LMkRBnci3QvsTrIFeBO4FaCqXkmyG3gVmAbuqqpPW1d3MriDagXwXHsAPAI8keQQgyOJTa2v95L8c+AP2nb/rKpmX1SXJJ1lnxsUVfXLJ1m1/iTb7wB2zFHfD1w3R/0jWtDMse5R4NHPG6Mk6ezxL7MlSV0GhSSpy6CQJHUZFJKkLoNCktRlUEiSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK6DApJUpdBIUnqMigkSV0GhSSpy6CQJHUZFJKkLoNCktQ1UlAk+cdJXkny/STfTPJjSS5J8nyS19vzxUPb353kUJLXktw0VL8+yYG27sEkafULkjzV6vuSrB5lvJKk0zfvoEhyBfCPgHVVdR1wHrAJ2A7srao1wN72miTXtPXXAhuAh5Kc17p7GNgKrGmPDa2+BXi/qq4GHgDum+94JUnzM+qpp/OBFUnOB34ceBvYCOxq63cBN7fljcCTVfVxVb0BHAJuSLISuLCqXqyqAh6f1Wamr6eB9TNHG5KkhXH+fBtW1Q+S/AvgTeD/At+uqm8nmaiqo22bo0kub02uAL4z1MWRVvukLc+uz7R5q/U1neQD4FLg3eGxJNnK4IiEiYkJpqam5vtjcfz48ZHaLxXOw8BSmYdta6dHaj+xYv59LIX5m7FU9ofTNe+gaNceNgJXAX8C/Ickv9JrMketOvVemxMLVTuBnQDr1q2rycnJzjD6pqamGKX9UuE8DCyVebhj+7Mjtd+2dpr7D8zv18Xh2yZHeu/FZKnsD6drlFNPfwt4o6r+uKo+Ab4F/HXgnXY6ifZ8rG1/BLhyqP0qBqeqjrTl2fUT2rTTWxcB740wZknSaRolKN4Ebkzy4+26wXrgILAH2Ny22Qw805b3AJvanUxXMbho/VI7TfVhkhtbP7fPajPT1y3AC+06hiRpgYxyjWJfkqeB7wLTwB8yOP3zRWB3ki0MwuTWtv0rSXYDr7bt76qqT1t3dwKPASuA59oD4BHgiSSHGBxJbJrveCVJ8zPvoACoqnuAe2aVP2ZwdDHX9juAHXPU9wPXzVH/iBY0kqTx8C+zJUldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK6DApJUpdBIUnqMigkSV0GhSSpy6CQJHWN9J3Z0rlo9fZnT3nbbWunueM0tpeWIo8oJEldBoUkqcugkCR1GRSSpC6DQpLU5V1PknSGnc6ddWfS4Xu/elb69YhCktRlUEiSukYKiiR/McnTSf5nkoNJ/lqSS5I8n+T19nzx0PZ3JzmU5LUkNw3Vr09yoK17MEla/YIkT7X6viSrRxmvJOn0jXpE8dvAf62qvwr8LHAQ2A7srao1wN72miTXAJuAa4ENwENJzmv9PAxsBda0x4ZW3wK8X1VXAw8A9404XknSaZp3UCS5EPhF4BGAqvqzqvoTYCOwq222C7i5LW8Enqyqj6vqDeAQcEOSlcCFVfViVRXw+Kw2M309DayfOdqQJC2MUe56+ingj4F/m+RngZeBrwMTVXUUoKqOJrm8bX8F8J2h9kda7ZO2PLs+0+at1td0kg+AS4F3hweSZCuDIxImJiaYmpqa9w91/PjxkdovFUt5HratnT7lbSdWnN72S9Uo87CU9qNT/Xcxrn3mbM31KEFxPvDzwK9V1b4kv007zXQScx0JVKfea3NioWonsBNg3bp1NTk52RlG39TUFKO0XyqW8jyczof8bVs7zf0HvIt8lHk4fNvkmR3MGJ3qv4txfZDk2ZrrUf4FHAGOVNW+9vppBkHxTpKV7WhiJXBsaPsrh9qvAt5u9VVz1IfbHElyPnAR8N4IY5a0wJba3xQsR/O+RlFV/xt4K8lPt9J64FVgD7C51TYDz7TlPcCmdifTVQwuWr/UTlN9mOTGdv3h9lltZvq6BXihXceQJC2QUY+pfw34RpIfBf4I+PsMwmd3ki3Am8CtAFX1SpLdDMJkGrirqj5t/dwJPAasAJ5rDxhcKH8iySEGRxKbRhyvJOk0jRQUVfU9YN0cq9afZPsdwI456vuB6+aof0QLGknSePiX2ZKkLoNCktRlUEiSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK6RvrObElarFZvf/aM97lt7TR3nIV+FzuPKCRJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK6vD1WY3M2bl+UdOZ5RCFJ6jIoJEldIwdFkvOS/GGS/9xeX5Lk+SSvt+eLh7a9O8mhJK8luWmofn2SA23dg0nS6hckearV9yVZPep4JUmn50wcUXwdODj0ejuwt6rWAHvba5JcA2wCrgU2AA8lOa+1eRjYCqxpjw2tvgV4v6quBh4A7jsD45UknYaRgiLJKuCrwL8ZKm8EdrXlXcDNQ/Unq+rjqnoDOATckGQlcGFVvVhVBTw+q81MX08D62eONiRJC2PUu55+C/gnwE8M1Saq6ihAVR1NcnmrXwF8Z2i7I632SVueXZ9p81brazrJB8ClwLvDg0iylcERCRMTE0xNTc37Bzp+/PhI7ZeKhZiHbWunz2r/Z8LEinNjnGeb8zCw2OfhbP2bnXdQJPk7wLGqejnJ5Kk0maNWnXqvzYmFqp3AToB169bV5OSpDGduU1NTjNJ+qViIeTgXPoVz29pp7j/gXeTOw8Bin4fDt02elX5H+Ym/DPzdJL8E/BhwYZJ/B7yTZGU7mlgJHGvbHwGuHGq/Cni71VfNUR9ucyTJ+cBFwHsjjFmSdJrmfY2iqu6uqlVVtZrBReoXqupXgD3A5rbZZuCZtrwH2NTuZLqKwUXrl9ppqg+T3NiuP9w+q81MX7e09/jMEYUk6ew5G8dQ9wK7k2wB3gRuBaiqV5LsBl4FpoG7qurT1uZO4DFgBfBcewA8AjyR5BCDI4lNZ2G8kqSOMxIUVTUFTLXl/wOsP8l2O4Adc9T3A9fNUf+IFjSSpPHwL7MlSV0GhSSpy6CQJHUZFJKkLoNCktRlUEiSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpK7F+w0cY3LgBx+M5Qt1Dt/71QV/T0k6FR5RSJK6DApJUpdBIUnqMigkSV0GhSSpy6CQJHUZFJKkLoNCktRlUEiSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpK55B0WSK5P8XpKDSV5J8vVWvyTJ80leb88XD7W5O8mhJK8luWmofn2SA23dg0nS6hckearV9yVZPcLPKkmah1GOKKaBbVX1M8CNwF1JrgG2A3urag2wt72mrdsEXAtsAB5Kcl7r62FgK7CmPTa0+hbg/aq6GngAuG+E8UqS5mHeQVFVR6vqu235Q+AgcAWwEdjVNtsF3NyWNwJPVtXHVfUGcAi4IclK4MKqerGqCnh8VpuZvp4G1s8cbUiSFsYZ+SrUdkro54B9wERVHYVBmCS5vG12BfCdoWZHWu2Ttjy7PtPmrdbXdJIPgEuBd2e9/1YGRyRMTEwwNTU1759lYgVsWzs97/bzNcqYz4bjx4+f9TGNY55P17j2h8XGeRhY7PNwtv7NjhwUSb4I/A7w61X1p53/8M+1ojr1XpsTC1U7gZ0A69atq8nJyc8Z9cn9y288w/0HFv6rxA/fNrng79kzNTXFKPN4Ksbx3eSna9va6bHsD4uN8zCw2OfhbP0eGemupyQ/wiAkvlFV32rld9rpJNrzsVY/Alw51HwV8Harr5qjfkKbJOcDFwHvjTJmSdLpGeWupwCPAAer6jeHVu0BNrflzcAzQ/VN7U6mqxhctH6pnab6MMmNrc/bZ7WZ6esW4IV2HUOStEBGOYb6MvCrwIEk32u13wDuBXYn2QK8CdwKUFWvJNkNvMrgjqm7qurT1u5O4DFgBfBce8AgiJ5IcojBkcSmEcYrSZqHeQdFVf135r6GALD+JG12ADvmqO8Hrpuj/hEtaCRJ4+FfZkuSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1LV4vyVcC2b19mc/U9u2dpo75qhLWn4MikVirl/WkrQYeOpJktRlUEiSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklS1zkRFEk2JHktyaEk28c9HklaThZ9UCQ5D/hXwN8GrgF+Ock14x2VJC0fiz4ogBuAQ1X1R1X1Z8CTwMYxj0mSlo1U1bjH0JXkFmBDVf2D9vpXgV+oqq8NbbMV2Npe/jTw2ghveRnw7gjtlwrnYcB5GHAeBpbyPPzlqvrJuVacC99HkTlqJ6RbVe0Edp6RN0v2V9W6M9HXucx5GHAeBpyHgeU6D+fCqacjwJVDr1cBb49pLJK07JwLQfEHwJokVyX5UWATsGfMY5KkZWPRn3qqqukkXwN+FzgPeLSqXjmLb3lGTmEtAc7DgPMw4DwMLMt5WPQXsyVJ43UunHqSJI2RQSFJ6jIoGj8mZCDJ4SQHknwvyf5xj2chJXk0ybEk3x+qXZLk+SSvt+eLxznGhXCSefinSX7Q9ovvJfmlcY5xISS5MsnvJTmY5JUkX2/1ZbdPGBT4MSFz+JtV9aVleL/4Y8CGWbXtwN6qWgPsba+Xusf47DwAPND2iy9V1X9Z4DGNwzSwrap+BrgRuKv9Xlh2+4RBMeDHhIiq+n3gvVnljcCutrwLuHkhxzQOJ5mHZaeqjlbVd9vyh8BB4AqW4T5hUAxcAbw19PpIqy1HBXw7ycvto1GWu4mqOgqDXxzA5WMezzh9Lcn/aKemlvzplmFJVgM/B+xjGe4TBsXA535MyDLy5ar6eQan4e5K8ovjHpAWhYeBvwJ8CTgK3D/W0SygJF8Efgf49ar603GPZxwMigE/JqSpqrfb8zHgPzI4LbecvZNkJUB7Pjbm8YxFVb1TVZ9W1Z8D/5plsl8k+REGIfGNqvpWKy+7fcKgGPBjQoAkX0jyEzPLwFeA7/dbLXl7gM1teTPwzBjHMjYzvxibv8cy2C+SBHgEOFhVvzm0atntE/5ldtNu9/st/v/HhOwY74gWXpKfYnAUAYOPd/n3y2keknwTmGTwUdLvAPcA/wnYDfwl4E3g1qpa0hd6TzIPkwxOOxVwGPiHM+fpl6okfwP4b8AB4M9b+TcYXKdYXvuEQSFJ6vHUkySpy6CQJHUZFJKkLoNCktRlUEiSugwKSVKXQSFJ6vp/SlzaLLvByAIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train['Hour'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "id": "Tj0j0qKruCpJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train['day'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "id": "23MyqzVMmz_-"
   },
   "outputs": [],
   "source": [
    "# 일단 id, person_rn, contents_open_dt 를 제거해야하는가? person_rn과 contents_rn 이 같은값을 가지는아이가 있음\n",
    "df_train = df_train.drop(['id','person_prefer_f','person_prefer_g','contents_rn','person_rn','contents_open_dt'], axis=1)\n",
    "df_test  = df_test.drop(['id','person_prefer_f','person_prefer_g','contents_rn','person_rn','contents_open_dt'], axis=1)\n",
    "#df_train = df_train.drop(['id','person_prefer_f','person_prefer_g','contents_open_dt'], axis=1)\n",
    "#df_test  = df_test.drop(['id','person_prefer_f','person_prefer_g','contents_open_dt'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "id": "gu_XH2vQq300"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['d_l_match_yn', 'd_m_match_yn', 'd_s_match_yn', 'h_l_match_yn',\n",
      "       'h_m_match_yn', 'h_s_match_yn', 'person_attribute_a',\n",
      "       'person_attribute_a_1', 'person_attribute_b', 'person_prefer_c',\n",
      "       'person_prefer_d_1', 'person_prefer_d_2', 'person_prefer_d_3',\n",
      "       'person_prefer_e', 'person_prefer_h_1', 'person_prefer_h_2',\n",
      "       'person_prefer_h_3', 'contents_attribute_i', 'contents_attribute_a',\n",
      "       'contents_attribute_j_1', 'contents_attribute_j',\n",
      "       'contents_attribute_c', 'contents_attribute_k', 'contents_attribute_l',\n",
      "       'contents_attribute_d', 'contents_attribute_m', 'contents_attribute_e',\n",
      "       'contents_attribute_h', 'target', 'person_prefer_d_1_n',\n",
      "       'person_prefer_d_1_s', 'person_prefer_d_1_m', 'person_prefer_d_1_l',\n",
      "       'person_prefer_d_2_n', 'person_prefer_d_2_s', 'person_prefer_d_2_m',\n",
      "       'person_prefer_d_2_l', 'person_prefer_d_3_n', 'person_prefer_d_3_s',\n",
      "       'person_prefer_d_3_m', 'person_prefer_d_3_l', 'contents_attribute_d_n',\n",
      "       'contents_attribute_d_s', 'contents_attribute_d_m',\n",
      "       'contents_attribute_d_l', 'person_prefer_h_1_l', 'person_prefer_h_1_m',\n",
      "       'person_prefer_h_2_l', 'person_prefer_h_2_m', 'person_prefer_h_3_l',\n",
      "       'person_prefer_h_3_m', 'contents_attribute_h_l',\n",
      "       'contents_attribute_h_m', 'contents_attribute_l_n',\n",
      "       'contents_attribute_l_s', 'contents_attribute_l_m',\n",
      "       'contents_attribute_l_l', 'person_count', 'contents_count', 'Hour',\n",
      "       'day'],\n",
      "      dtype='object')\n",
      "Index(['d_l_match_yn', 'd_m_match_yn', 'd_s_match_yn', 'h_l_match_yn',\n",
      "       'h_m_match_yn', 'h_s_match_yn', 'person_attribute_a',\n",
      "       'person_attribute_a_1', 'person_attribute_b', 'person_prefer_c',\n",
      "       'person_prefer_d_1', 'person_prefer_d_2', 'person_prefer_d_3',\n",
      "       'person_prefer_e', 'person_prefer_h_1', 'person_prefer_h_2',\n",
      "       'person_prefer_h_3', 'contents_attribute_i', 'contents_attribute_a',\n",
      "       'contents_attribute_j_1', 'contents_attribute_j',\n",
      "       'contents_attribute_c', 'contents_attribute_k', 'contents_attribute_l',\n",
      "       'contents_attribute_d', 'contents_attribute_m', 'contents_attribute_e',\n",
      "       'contents_attribute_h', 'person_prefer_d_1_n', 'person_prefer_d_1_s',\n",
      "       'person_prefer_d_1_m', 'person_prefer_d_1_l', 'person_prefer_d_2_n',\n",
      "       'person_prefer_d_2_s', 'person_prefer_d_2_m', 'person_prefer_d_2_l',\n",
      "       'person_prefer_d_3_n', 'person_prefer_d_3_s', 'person_prefer_d_3_m',\n",
      "       'person_prefer_d_3_l', 'contents_attribute_d_n',\n",
      "       'contents_attribute_d_s', 'contents_attribute_d_m',\n",
      "       'contents_attribute_d_l', 'person_prefer_h_1_l', 'person_prefer_h_1_m',\n",
      "       'person_prefer_h_2_l', 'person_prefer_h_2_m', 'person_prefer_h_3_l',\n",
      "       'person_prefer_h_3_m', 'contents_attribute_h_l',\n",
      "       'contents_attribute_h_m', 'contents_attribute_l_n',\n",
      "       'contents_attribute_l_s', 'contents_attribute_l_m',\n",
      "       'contents_attribute_l_l', 'person_count', 'contents_count', 'Hour',\n",
      "       'day'],\n",
      "      dtype='object')\n",
      "61\n"
     ]
    }
   ],
   "source": [
    "# 제대로 제거됐나 확인\n",
    "print(df_train.columns)\n",
    "print(df_test.columns)\n",
    "print(len(df_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "id": "Q-HCUr4Uq55J"
   },
   "outputs": [],
   "source": [
    "# data를 train, valid, test로 나누기\n",
    "if \"Set\" not in df_train.columns:\n",
    "    df_train[\"Set\"] = np.random.choice([\"train\",'valid'], p =[0.9,0.1], size=(df_train.shape[0],))\n",
    "\n",
    "train_indices = df_train[df_train.Set==\"train\"].index\n",
    "valid_indices = df_train[df_train.Set==\"valid\"].index\n",
    "#test_indices = df_train[df_train.Set==\"test\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "id": "uUK-kfLzrQzF",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_l_match_yn 2\n",
      "d_m_match_yn 2\n",
      "d_s_match_yn 2\n",
      "h_l_match_yn 2\n",
      "h_m_match_yn 2\n",
      "h_s_match_yn 2\n",
      "person_attribute_a 2\n",
      "person_attribute_a_1 8\n",
      "person_attribute_b 6\n",
      "person_prefer_c 5\n",
      "person_prefer_d_1 1093\n",
      "person_prefer_d_2 1081\n",
      "person_prefer_d_3 1043\n",
      "person_prefer_e 12\n",
      "person_prefer_h_1 279\n",
      "person_prefer_h_2 279\n",
      "person_prefer_h_3 279\n",
      "contents_attribute_i 3\n",
      "contents_attribute_a 3\n",
      "contents_attribute_j_1 9\n",
      "contents_attribute_j 2\n",
      "contents_attribute_c 4\n",
      "contents_attribute_k 2\n",
      "contents_attribute_l 1752\n",
      "contents_attribute_d 1065\n",
      "contents_attribute_m 5\n",
      "contents_attribute_e 12\n",
      "contents_attribute_h 250\n",
      "person_prefer_d_1_n 443\n",
      "person_prefer_d_1_s 137\n",
      "person_prefer_d_1_m 36\n",
      "person_prefer_d_1_l 11\n",
      "person_prefer_d_2_n 435\n",
      "person_prefer_d_2_s 137\n",
      "person_prefer_d_2_m 36\n",
      "person_prefer_d_2_l 11\n",
      "person_prefer_d_3_n 420\n",
      "person_prefer_d_3_s 136\n",
      "person_prefer_d_3_m 36\n",
      "person_prefer_d_3_l 11\n",
      "contents_attribute_d_n 431\n",
      "contents_attribute_d_s 137\n",
      "contents_attribute_d_m 36\n",
      "contents_attribute_d_l 11\n",
      "person_prefer_h_1_l 19\n",
      "person_prefer_h_1_m 246\n",
      "person_prefer_h_2_l 19\n",
      "person_prefer_h_2_m 246\n",
      "person_prefer_h_3_l 19\n",
      "person_prefer_h_3_m 246\n",
      "contents_attribute_h_l 17\n",
      "contents_attribute_h_m 228\n",
      "contents_attribute_l_n 736\n",
      "contents_attribute_l_s 305\n",
      "contents_attribute_l_m 79\n",
      "contents_attribute_l_l 21\n",
      "person_count 20\n",
      "contents_count 29\n",
      "Hour 24\n",
      "day 7\n"
     ]
    }
   ],
   "source": [
    "ordinal = []#['person_count','contents_count','person_attribute_a_1', 'person_attribute_b', 'person_prefer_e', 'contents_attribute_e']\n",
    "\n",
    "categorical_columns = []\n",
    "categorical_dims =  {}\n",
    "for col in df_train.columns:\n",
    "    if col not in ordinal+['Set', 'target']:\n",
    "        print(col, df_train[col].nunique())\n",
    "        l_enc = LabelEncoder()\n",
    "        df_train[col] = l_enc.fit_transform(df_train[col].values)\n",
    "        categorical_columns.append(col)\n",
    "        categorical_dims[col] = len(l_enc.classes_)\n",
    "        df_test[col]  = l_enc.fit_transform(df_test[col].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "id": "VVOV2cw8ryKJ"
   },
   "outputs": [],
   "source": [
    "unused_feat = ['Set']\n",
    "\n",
    "features = [ col for col in df_train.columns if col not in unused_feat+['target']] \n",
    "\n",
    "cat_idxs = [ i for i, f in enumerate(features) if f in categorical_columns]\n",
    "\n",
    "cat_dims = [ categorical_dims[f] for i, f in enumerate(features) if f in categorical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''       PCA \n",
    "mca = prince.MCA(\n",
    "    n_components=5,\n",
    "    random_state=2022,\n",
    "    n_iter=15\n",
    ")\n",
    "mca.fit(df_train[features])\n",
    "main_mca = mca.transform(df_train[features])\n",
    "df_test = mca.transform(df_test)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6808080832994885,\n",
       " 0.22062658963457993,\n",
       " 0.062048424877434234,\n",
       " 0.02231845157060019,\n",
       " 0.014198450617897188]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[i/sum(mca.eigenvalues_) for i in mca.eigenvalues_]##### 5개 사용이 좋아보임\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5\n"
     ]
    }
   ],
   "source": [
    "#print(len(main_mca.columns),len(df_test.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EN-Qzs9XsA5T"
   },
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "id": "Kvxgwfk8scO-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nX_train = main_mca.values[train_indices]\\ny_train = df_train['target'].values[train_indices]\\n\\n\\nX_valid = main_mca.values[valid_indices]\\ny_valid = df_train['target'].values[valid_indices]\\n\\nX_test = main_mca.values[test_indices]\\ny_test = df_train['target'].values[test_indices]\\n\\ndf_test = df_test.values\\n\""
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################################### CATBOOST\n",
    "X_train = df_train[features].iloc[train_indices]\n",
    "y_train = df_train['target'].iloc[train_indices]\n",
    "\n",
    "X_valid = df_train[features].iloc[valid_indices]\n",
    "y_valid = df_train['target'].iloc[valid_indices]\n",
    "\n",
    "\n",
    "X_test = df_train[features].iloc[test_indices]\n",
    "y_test = df_train['target'].iloc[test_indices]\n",
    "\n",
    "\n",
    "################################ tabnet\n",
    "#X_train = df_train[features].values[train_indices]\n",
    "#y_train = df_train['target'].values[train_indices]\n",
    "#X_valid = df_train[features].values[valid_indices]\n",
    "#y_valid = df_train['target'].values[valid_indices]\n",
    "\n",
    "#X_test = df_train[features].values[test_indices]\n",
    "#y_test = df_train['target'].values[test_indices]\n",
    "\n",
    "\n",
    "'''\n",
    "X_train = main_mca.values[train_indices]\n",
    "y_train = df_train['target'].values[train_indices]\n",
    "\n",
    "\n",
    "X_valid = main_mca.values[valid_indices]\n",
    "y_valid = df_train['target'].values[valid_indices]\n",
    "\n",
    "X_test = main_mca.values[test_indices]\n",
    "y_test = df_train['target'].values[test_indices]\n",
    "\n",
    "df_test = df_test.values\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "id": "H8a0J_QL0a1A"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n",
      "epoch 0  | loss: 3.08934 | val_0_unsup_loss: 0.9118  |  0:00:19s\n",
      "epoch 10 | loss: 0.91131 | val_0_unsup_loss: 0.77462 |  0:03:32s\n",
      "epoch 20 | loss: 0.90451 | val_0_unsup_loss: 0.80782 |  0:06:43s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 13 and best_val_0_unsup_loss = 0.76964\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "N_D = 8    ### 8~64 , 높을수록 overfitting 위험 ㄴ\n",
    "N_A = 8       ### N_D와 같게\n",
    "N_INDEP = 2      ### 1~5\n",
    "N_SHARED = 2      ### 1~5\n",
    "N_STEPS = 3       ### 3~10\n",
    "\n",
    "unsupervised_model = TabNetPretrainer(\n",
    "    n_d=N_D, n_a=N_A, n_steps=N_STEPS,  #0.2,\n",
    "    n_independent=N_INDEP, n_shared=N_SHARED,\n",
    "    optimizer_fn=torch.optim.AdamW,\n",
    "    optimizer_params=dict(lr=1e-2,weight_decay=1e-5),\n",
    "    mask_type='sparsemax' # \"sparsemax\",\n",
    "\n",
    ")\n",
    "\n",
    "unsupervised_model.fit(\n",
    "    X_train=X_train,\n",
    "    eval_set=[X_valid],\n",
    "    pretraining_ratio=0.8,\n",
    "    patience=15, batch_size=2048, virtual_batch_size=128,\n",
    "    num_workers=0 ,\n",
    "    max_epochs=101\n",
    ")\n",
    "\n",
    "tabnet_params = dict(n_d=N_D, n_a=N_A, n_steps=N_STEPS,  #0.2,\n",
    "                         n_independent=N_INDEP, n_shared=N_SHARED,\n",
    "                         lambda_sparse=0., optimizer_fn=torch.optim.Adam,\n",
    "                         optimizer_params=dict(lr=2e-2, # 2e-2\n",
    "                                               weight_decay=1e-5),\n",
    "                          scheduler_params={'step_size':50, 'gamma':0.90},\n",
    "                          scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                          mask_type=\"entmax\",\n",
    "                         \n",
    "                          verbose=10,\n",
    "                         )\n",
    "\n",
    "pretrainer = TabNetPretrainer(**tabnet_params)\n",
    "\n",
    "pretrainer.fit(\n",
    "    X_train=X_train,\n",
    "    eval_set=[X_valid],\n",
    "    pretraining_ratio=0.8,\n",
    "    patience=15, batch_size=2048, virtual_batch_size=128,\n",
    "    num_workers=0 ,\n",
    "    max_epochs=101\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "id": "J61tOGQ_sRLS"
   },
   "outputs": [],
   "source": [
    "class F1_Score(Metric):\n",
    "    def __init__(self):\n",
    "        self._name = \"f1\"\n",
    "        self._maximize = True\n",
    "    \n",
    "    def __call__(self, y_true, y_score):\n",
    "        score = f1_score(y_true, y_score[:,1]>0.5)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "id": "cP520B5ksTa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n"
     ]
    }
   ],
   "source": [
    "# setting hyperparameters tabnet\n",
    "max_epochs = 100\n",
    "patience = 15\n",
    "batch_size = 2048\n",
    "virtual_batch_size = 128\n",
    "num_workers = 0\n",
    "weights = 0\n",
    "\n",
    "tabnet = TabNetClassifier(#cat_idxs=cat_idxs,\n",
    "                          cat_idxs = list(range(0,len(main_mca.columns))),\n",
    "#                          cat_dims=cat_dims,\n",
    "                          n_d=N_D, n_a=N_A, n_steps=N_STEPS,\n",
    "                         n_independent=N_INDEP, n_shared=N_SHARED,\n",
    "                          optimizer_fn=torch.optim.Adam,\n",
    "                          optimizer_params=dict(lr=2e-2, # 2e-2\n",
    "                                               weight_decay=1e-4),\n",
    "                          scheduler_params={'step_size':15, 'gamma':0.90},\n",
    "                          scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                          #scheduler_params=dict(mode=\"min\",\n",
    "                          #                      patience=5,\n",
    "                          #                      min_lr=1e-5,\n",
    "                          #                      factor=0.9,),\n",
    "                          #scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau, \n",
    "                          mask_type='entmax', #'sparsemax',  라는 옵션도 있음\n",
    "                          device_name=device\n",
    "                          )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "id": "I46-D--hsU8P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from unsupervised pretraining\n",
      "epoch 0  | loss: 0.68871 | train_auc: 0.55996 | train_f1: 0.65065 | valid_auc: 0.55748 | valid_f1: 0.64937 |  0:00:19s\n",
      "epoch 1  | loss: 0.68683 | train_auc: 0.53381 | train_f1: 0.56405 | valid_auc: 0.5376  | valid_f1: 0.56337 |  0:00:39s\n",
      "epoch 2  | loss: 0.68635 | train_auc: 0.53083 | train_f1: 0.52789 | valid_auc: 0.53264 | valid_f1: 0.52558 |  0:00:59s\n",
      "epoch 3  | loss: 0.68634 | train_auc: 0.55924 | train_f1: 0.59542 | valid_auc: 0.55994 | valid_f1: 0.59109 |  0:01:19s\n",
      "epoch 4  | loss: 0.68592 | train_auc: 0.56985 | train_f1: 0.64353 | valid_auc: 0.56414 | valid_f1: 0.63986 |  0:01:39s\n",
      "epoch 5  | loss: 0.68571 | train_auc: 0.56169 | train_f1: 0.54531 | valid_auc: 0.5631  | valid_f1: 0.54142 |  0:01:59s\n",
      "epoch 6  | loss: 0.68582 | train_auc: 0.56603 | train_f1: 0.60639 | valid_auc: 0.55925 | valid_f1: 0.59978 |  0:02:19s\n",
      "epoch 7  | loss: 0.68566 | train_auc: 0.52734 | train_f1: 0.40662 | valid_auc: 0.52714 | valid_f1: 0.41013 |  0:02:39s\n",
      "epoch 8  | loss: 0.686   | train_auc: 0.55665 | train_f1: 0.36838 | valid_auc: 0.55707 | valid_f1: 0.37238 |  0:02:59s\n",
      "epoch 9  | loss: 0.68561 | train_auc: 0.57037 | train_f1: 0.61324 | valid_auc: 0.56642 | valid_f1: 0.60841 |  0:03:19s\n",
      "epoch 10 | loss: 0.68583 | train_auc: 0.54426 | train_f1: 0.2123  | valid_auc: 0.54866 | valid_f1: 0.21604 |  0:03:39s\n",
      "epoch 11 | loss: 0.68633 | train_auc: 0.57123 | train_f1: 0.59995 | valid_auc: 0.56786 | valid_f1: 0.59872 |  0:03:59s\n",
      "epoch 12 | loss: 0.68576 | train_auc: 0.57308 | train_f1: 0.55736 | valid_auc: 0.56962 | valid_f1: 0.55593 |  0:04:19s\n",
      "epoch 13 | loss: 0.68553 | train_auc: 0.56985 | train_f1: 0.54464 | valid_auc: 0.57003 | valid_f1: 0.54134 |  0:04:38s\n",
      "epoch 14 | loss: 0.68538 | train_auc: 0.567   | train_f1: 0.52396 | valid_auc: 0.56557 | valid_f1: 0.52316 |  0:04:58s\n",
      "epoch 15 | loss: 0.68538 | train_auc: 0.56557 | train_f1: 0.60854 | valid_auc: 0.56208 | valid_f1: 0.60224 |  0:05:18s\n",
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 0 and best_valid_f1 = 0.64937\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    }
   ],
   "source": [
    "# fitting model tabnet\n",
    "tabnet.fit(\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    #eval_set = [(X_valid,y_valid)],\n",
    "    eval_name=['train','valid'],\n",
    "    eval_metric=['auc','f1'],\n",
    "    max_epochs=max_epochs, patience=patience,\n",
    "    batch_size=batch_size, virtual_batch_size=virtual_batch_size,\n",
    "    num_workers=num_workers,\n",
    "    weights=weights,\n",
    "    from_unsupervised=pretrainer,\n",
    "    drop_last=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "id": "zdxFmkjXtNwE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5569100746674055 0.6674009402283412\n"
     ]
    }
   ],
   "source": [
    "################ tabnet\n",
    "preds = tabnet.predict_proba(X_test)\n",
    "test_auc = roc_auc_score(y_true=y_test, y_score=preds[:,1])\n",
    "test_f1 = f1_score(y_test, preds[:,1]>0.4)\n",
    "print(test_auc, test_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "id": "Gb_8gTdMYlfp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6683462203342133 0.0\n"
     ]
    }
   ],
   "source": [
    "######################### tabnet\n",
    "f1=[]\n",
    "for i in np.linspace(0,1,1001):\n",
    "    f1.append(f1_score(y_test, preds[:,1]>i))\n",
    "thres = np.linspace(0,1,1001)[f1.index(max(f1))]\n",
    "print(max(f1) , thres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "id": "yyIfFgYj2DMp"
   },
   "outputs": [],
   "source": [
    "\n",
    "# CatBoost 모델링\n",
    "def catboost_modeling(X_train, y_train, X_test, grow_policy, depth, learning_rate, l2_leaf_reg, random_seed, n):\n",
    "  \n",
    "  # 빈 Series인 test_pred 생성\n",
    "  test_pred = pd.Series([0 for x in range(len(X_test))], index=X_test.index)\n",
    "  \n",
    "  # 10-fold 모델링을 n회 반복할 것\n",
    "  for i in range(n):\n",
    "    kf = KFold(n_splits=5, random_state=random_seed+i,shuffle=True)\n",
    "    for train_index, valid_index in kf.split(X_train):\n",
    "      train_X, train_y = X_train.iloc[train_index], y_train.iloc[train_index]\n",
    "      valid_X, valid_y = X_train.iloc[valid_index], y_train.iloc[valid_index]\n",
    "      \n",
    "      # catBoost(grow_policy='Depthwise')\n",
    "      model = CatBoostClassifier(eval_metric = 'F1',              # F1로 성능 측정\n",
    "                                 iterations = 5000,               # 반복횟수 최대 5000\n",
    "                                 #metric_period = 25000,            # 중간결과 출력X\n",
    "                                 early_stopping_rounds = 200,     # 1000iteration 동안 F1 증가 없으면 학습 중단\n",
    "                                 task_type = 'CPU',                # GPU/CPU 사용\n",
    "                                 grow_policy = grow_policy,        # 트리 노드 생성 방식\n",
    "                                                                   # 1) Depthwise(지정한 depth에 이를 때까지 level 순으로 노드 분할)\n",
    "                                 cat_features = features,#<- Features          # 2) Lossguide(loss 변화가 큰 순으로 노드 분할)\n",
    "                                 depth = depth,                    # 트리 깊이 4~10\n",
    "                                 learning_rate = learning_rate,    # 러닝레이트\n",
    "                                 l2_leaf_reg = l2_leaf_reg,        # L2 정규화\n",
    "                                 random_seed = random_seed+i,      # 랜덤시드 고정\n",
    "                                 )\n",
    "      # 모델 학습\n",
    "      model.fit(train_X, train_y, eval_set=(valid_X, valid_y),verbose=100)\n",
    "    \n",
    "      # 모델 적용\n",
    "      test_pred += model.predict_proba(X_test)[:,1] /(5*n)\n",
    "  # 설정된 디렉토리에 결과물 저장\n",
    "  #submission = pd.read_csv(SUBMIT_PATH + '/sample_submission.csv',index_col=0)\n",
    "  #submission = pd.DataFrame(data=test_pred, columns=sample_submission.columns, index=sample_submission.index)\n",
    "  #submission.to_csv(SUBMIT_PATH + '/CatBoost_'+grow_policy+'_'+str(depth)+'.csv', index=True)\n",
    "\n",
    "  return test_pred\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true,
    "id": "1xbUsypO2Y50"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Custom logger is already specified. Specify more than one logger at same time is not thread safe."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6487533\ttest: 0.6515949\tbest: 0.6515949 (0)\ttotal: 667ms\tremaining: 55m 33s\n",
      "100:\tlearn: 0.6318919\ttest: 0.6403694\tbest: 0.6517182 (4)\ttotal: 35s\tremaining: 28m 17s\n",
      "200:\tlearn: 0.6435989\ttest: 0.6549996\tbest: 0.6550741 (198)\ttotal: 1m 9s\tremaining: 27m 46s\n",
      "300:\tlearn: 0.6485420\ttest: 0.6606388\tbest: 0.6606388 (300)\ttotal: 1m 44s\tremaining: 27m 15s\n",
      "400:\tlearn: 0.6525006\ttest: 0.6651616\tbest: 0.6651616 (400)\ttotal: 2m 19s\tremaining: 26m 43s\n",
      "500:\tlearn: 0.6554487\ttest: 0.6688513\tbest: 0.6689485 (491)\ttotal: 2m 52s\tremaining: 25m 51s\n",
      "600:\tlearn: 0.6574613\ttest: 0.6718551\tbest: 0.6719692 (587)\ttotal: 3m 26s\tremaining: 25m 9s\n",
      "700:\tlearn: 0.6595422\ttest: 0.6729914\tbest: 0.6730393 (696)\ttotal: 4m\tremaining: 24m 36s\n",
      "800:\tlearn: 0.6612467\ttest: 0.6745401\tbest: 0.6745401 (800)\ttotal: 4m 36s\tremaining: 24m 7s\n",
      "900:\tlearn: 0.6622708\ttest: 0.6757058\tbest: 0.6757475 (896)\ttotal: 5m 11s\tremaining: 23m 37s\n",
      "1000:\tlearn: 0.6630235\ttest: 0.6768809\tbest: 0.6768809 (1000)\ttotal: 5m 46s\tremaining: 23m 5s\n",
      "1100:\tlearn: 0.6634806\ttest: 0.6773693\tbest: 0.6774920 (1060)\ttotal: 6m 21s\tremaining: 22m 30s\n",
      "1200:\tlearn: 0.6644214\ttest: 0.6777433\tbest: 0.6778035 (1190)\ttotal: 6m 55s\tremaining: 21m 54s\n",
      "1300:\tlearn: 0.6651384\ttest: 0.6779210\tbest: 0.6780985 (1292)\ttotal: 7m 30s\tremaining: 21m 20s\n",
      "1400:\tlearn: 0.6657318\ttest: 0.6782274\tbest: 0.6783186 (1398)\ttotal: 8m 6s\tremaining: 20m 50s\n",
      "1500:\tlearn: 0.6663084\ttest: 0.6788792\tbest: 0.6789727 (1499)\ttotal: 8m 43s\tremaining: 20m 19s\n",
      "1600:\tlearn: 0.6666792\ttest: 0.6793275\tbest: 0.6793797 (1586)\ttotal: 9m 18s\tremaining: 19m 46s\n",
      "1700:\tlearn: 0.6673311\ttest: 0.6800323\tbest: 0.6800753 (1697)\ttotal: 9m 54s\tremaining: 19m 12s\n",
      "1800:\tlearn: 0.6676840\ttest: 0.6803576\tbest: 0.6806449 (1750)\ttotal: 10m 31s\tremaining: 18m 42s\n",
      "1900:\tlearn: 0.6678685\ttest: 0.6803563\tbest: 0.6806449 (1750)\ttotal: 11m 7s\tremaining: 18m 7s\n",
      "2000:\tlearn: 0.6682158\ttest: 0.6806701\tbest: 0.6807312 (1994)\ttotal: 11m 42s\tremaining: 17m 32s\n",
      "2100:\tlearn: 0.6685150\ttest: 0.6810511\tbest: 0.6810511 (2100)\ttotal: 12m 18s\tremaining: 16m 59s\n",
      "2200:\tlearn: 0.6687785\ttest: 0.6812495\tbest: 0.6813731 (2136)\ttotal: 12m 56s\tremaining: 16m 26s\n",
      "2300:\tlearn: 0.6689076\ttest: 0.6817472\tbest: 0.6817911 (2291)\ttotal: 13m 31s\tremaining: 15m 52s\n",
      "2400:\tlearn: 0.6690848\ttest: 0.6821890\tbest: 0.6822175 (2398)\ttotal: 14m 8s\tremaining: 15m 18s\n",
      "2500:\tlearn: 0.6692890\ttest: 0.6820302\tbest: 0.6823412 (2462)\ttotal: 14m 44s\tremaining: 14m 43s\n",
      "2600:\tlearn: 0.6696630\ttest: 0.6824854\tbest: 0.6824854 (2600)\ttotal: 15m 20s\tremaining: 14m 8s\n",
      "2700:\tlearn: 0.6698100\ttest: 0.6826024\tbest: 0.6827071 (2695)\ttotal: 15m 55s\tremaining: 13m 33s\n",
      "2800:\tlearn: 0.6699912\ttest: 0.6827569\tbest: 0.6829222 (2745)\ttotal: 16m 31s\tremaining: 12m 58s\n",
      "2900:\tlearn: 0.6701934\ttest: 0.6830139\tbest: 0.6830139 (2900)\ttotal: 17m 7s\tremaining: 12m 23s\n",
      "3000:\tlearn: 0.6704013\ttest: 0.6829030\tbest: 0.6830139 (2900)\ttotal: 17m 45s\tremaining: 11m 49s\n",
      "3100:\tlearn: 0.6705997\ttest: 0.6831035\tbest: 0.6831319 (3089)\ttotal: 18m 22s\tremaining: 11m 15s\n",
      "3200:\tlearn: 0.6707323\ttest: 0.6833110\tbest: 0.6833188 (3198)\ttotal: 19m\tremaining: 10m 40s\n",
      "3300:\tlearn: 0.6709838\ttest: 0.6830325\tbest: 0.6834032 (3220)\ttotal: 19m 37s\tremaining: 10m 5s\n",
      "3400:\tlearn: 0.6712772\ttest: 0.6832314\tbest: 0.6834032 (3220)\ttotal: 20m 14s\tremaining: 9m 30s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.6834032164\n",
      "bestIteration = 3220\n",
      "\n",
      "Shrink model to first 3221 iterations.\n",
      "0:\tlearn: 0.6493224\ttest: 0.6495847\tbest: 0.6495847 (0)\ttotal: 430ms\tremaining: 35m 51s\n",
      "100:\tlearn: 0.6352681\ttest: 0.6436345\tbest: 0.6495847 (0)\ttotal: 37.4s\tremaining: 30m 15s\n",
      "200:\tlearn: 0.6453831\ttest: 0.6550696\tbest: 0.6550696 (200)\ttotal: 1m 17s\tremaining: 31m 1s\n",
      "300:\tlearn: 0.6504648\ttest: 0.6613381\tbest: 0.6613381 (300)\ttotal: 1m 58s\tremaining: 30m 45s\n",
      "400:\tlearn: 0.6543121\ttest: 0.6652628\tbest: 0.6652628 (400)\ttotal: 2m 37s\tremaining: 30m 6s\n",
      "500:\tlearn: 0.6570880\ttest: 0.6678511\tbest: 0.6679925 (496)\ttotal: 3m 14s\tremaining: 29m 7s\n",
      "600:\tlearn: 0.6589792\ttest: 0.6695078\tbest: 0.6695646 (599)\ttotal: 3m 52s\tremaining: 28m 23s\n",
      "700:\tlearn: 0.6605716\ttest: 0.6711899\tbest: 0.6713943 (696)\ttotal: 4m 29s\tremaining: 27m 29s\n",
      "800:\tlearn: 0.6618323\ttest: 0.6719643\tbest: 0.6719891 (765)\ttotal: 5m 6s\tremaining: 26m 45s\n",
      "900:\tlearn: 0.6630069\ttest: 0.6733030\tbest: 0.6733030 (900)\ttotal: 5m 42s\tremaining: 25m 59s\n",
      "1000:\tlearn: 0.6636143\ttest: 0.6736829\tbest: 0.6739530 (996)\ttotal: 6m 18s\tremaining: 25m 10s\n",
      "1100:\tlearn: 0.6642791\ttest: 0.6746736\tbest: 0.6748086 (1097)\ttotal: 6m 53s\tremaining: 24m 25s\n",
      "1200:\tlearn: 0.6648936\ttest: 0.6753782\tbest: 0.6755952 (1197)\ttotal: 7m 31s\tremaining: 23m 47s\n",
      "1300:\tlearn: 0.6653691\ttest: 0.6754068\tbest: 0.6756231 (1265)\ttotal: 8m 6s\tremaining: 23m 4s\n",
      "1400:\tlearn: 0.6660289\ttest: 0.6763438\tbest: 0.6764144 (1398)\ttotal: 8m 43s\tremaining: 22m 25s\n",
      "1500:\tlearn: 0.6665309\ttest: 0.6766728\tbest: 0.6767920 (1477)\ttotal: 9m 20s\tremaining: 21m 47s\n",
      "1600:\tlearn: 0.6669346\ttest: 0.6770843\tbest: 0.6771976 (1585)\ttotal: 10m 1s\tremaining: 21m 16s\n",
      "1700:\tlearn: 0.6671953\ttest: 0.6776348\tbest: 0.6777759 (1691)\ttotal: 10m 38s\tremaining: 20m 37s\n",
      "1800:\tlearn: 0.6678114\ttest: 0.6777787\tbest: 0.6779408 (1780)\ttotal: 11m 14s\tremaining: 19m 58s\n",
      "1900:\tlearn: 0.6680453\ttest: 0.6784206\tbest: 0.6786316 (1881)\ttotal: 11m 52s\tremaining: 19m 20s\n",
      "2000:\tlearn: 0.6684078\ttest: 0.6787985\tbest: 0.6789177 (1995)\ttotal: 12m 29s\tremaining: 18m 42s\n",
      "2100:\tlearn: 0.6688561\ttest: 0.6788335\tbest: 0.6789958 (2007)\ttotal: 13m 8s\tremaining: 18m 7s\n",
      "2200:\tlearn: 0.6690495\ttest: 0.6791664\tbest: 0.6792932 (2175)\ttotal: 13m 46s\tremaining: 17m 30s\n",
      "2300:\tlearn: 0.6694369\ttest: 0.6791391\tbest: 0.6793796 (2259)\ttotal: 14m 23s\tremaining: 16m 52s\n",
      "2400:\tlearn: 0.6696583\ttest: 0.6796071\tbest: 0.6796468 (2382)\ttotal: 15m\tremaining: 16m 14s\n",
      "2500:\tlearn: 0.6700224\ttest: 0.6797751\tbest: 0.6798387 (2496)\ttotal: 15m 38s\tremaining: 15m 37s\n",
      "2600:\tlearn: 0.6702525\ttest: 0.6796782\tbest: 0.6799518 (2559)\ttotal: 16m 15s\tremaining: 14m 59s\n",
      "2700:\tlearn: 0.6704114\ttest: 0.6798904\tbest: 0.6800392 (2689)\ttotal: 16m 52s\tremaining: 14m 21s\n",
      "2800:\tlearn: 0.6706643\ttest: 0.6801395\tbest: 0.6802299 (2770)\ttotal: 17m 29s\tremaining: 13m 44s\n",
      "2900:\tlearn: 0.6710726\ttest: 0.6801979\tbest: 0.6803108 (2880)\ttotal: 18m 7s\tremaining: 13m 7s\n",
      "3000:\tlearn: 0.6713227\ttest: 0.6803754\tbest: 0.6804812 (2996)\ttotal: 18m 45s\tremaining: 12m 29s\n",
      "3100:\tlearn: 0.6714206\ttest: 0.6805085\tbest: 0.6805788 (3097)\ttotal: 19m 23s\tremaining: 11m 52s\n",
      "3200:\tlearn: 0.6715864\ttest: 0.6806691\tbest: 0.6807885 (3181)\ttotal: 20m 1s\tremaining: 11m 15s\n",
      "3300:\tlearn: 0.6717586\ttest: 0.6808279\tbest: 0.6808647 (3273)\ttotal: 20m 38s\tremaining: 10m 37s\n",
      "3400:\tlearn: 0.6719683\ttest: 0.6806768\tbest: 0.6808937 (3339)\ttotal: 21m 15s\tremaining: 9m 59s\n",
      "3500:\tlearn: 0.6720615\ttest: 0.6806605\tbest: 0.6808937 (3339)\ttotal: 21m 53s\tremaining: 9m 22s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.6808937023\n",
      "bestIteration = 3339\n",
      "\n",
      "Shrink model to first 3340 iterations.\n",
      "0:\tlearn: 0.6484045\ttest: 0.6489407\tbest: 0.6489407 (0)\ttotal: 890ms\tremaining: 1h 14m 7s\n",
      "100:\tlearn: 0.6317014\ttest: 0.6390179\tbest: 0.6489407 (0)\ttotal: 35.2s\tremaining: 28m 27s\n",
      "200:\tlearn: 0.6436448\ttest: 0.6538183\tbest: 0.6538183 (200)\ttotal: 1m 15s\tremaining: 30m 1s\n",
      "300:\tlearn: 0.6491941\ttest: 0.6605948\tbest: 0.6605948 (300)\ttotal: 1m 54s\tremaining: 29m 41s\n",
      "400:\tlearn: 0.6532023\ttest: 0.6651774\tbest: 0.6651774 (400)\ttotal: 2m 33s\tremaining: 29m 22s\n",
      "500:\tlearn: 0.6561452\ttest: 0.6679795\tbest: 0.6679795 (500)\ttotal: 3m 10s\tremaining: 28m 28s\n",
      "600:\tlearn: 0.6579573\ttest: 0.6700338\tbest: 0.6701049 (594)\ttotal: 3m 47s\tremaining: 27m 48s\n",
      "700:\tlearn: 0.6600417\ttest: 0.6718119\tbest: 0.6721505 (689)\ttotal: 4m 25s\tremaining: 27m 9s\n",
      "800:\tlearn: 0.6607987\ttest: 0.6737309\tbest: 0.6738016 (797)\ttotal: 5m 3s\tremaining: 26m 32s\n",
      "900:\tlearn: 0.6620198\ttest: 0.6743891\tbest: 0.6744685 (876)\ttotal: 5m 41s\tremaining: 25m 51s\n",
      "1000:\tlearn: 0.6628870\ttest: 0.6755397\tbest: 0.6755959 (997)\ttotal: 6m 22s\tremaining: 25m 26s\n",
      "1100:\tlearn: 0.6635709\ttest: 0.6761653\tbest: 0.6763073 (1094)\ttotal: 7m\tremaining: 24m 49s\n",
      "1200:\tlearn: 0.6641534\ttest: 0.6769536\tbest: 0.6770041 (1193)\ttotal: 7m 40s\tremaining: 24m 18s\n",
      "1300:\tlearn: 0.6647924\ttest: 0.6770772\tbest: 0.6771894 (1235)\ttotal: 8m 19s\tremaining: 23m 40s\n",
      "1400:\tlearn: 0.6653110\ttest: 0.6774541\tbest: 0.6774895 (1399)\ttotal: 8m 59s\tremaining: 23m 6s\n",
      "1500:\tlearn: 0.6659032\ttest: 0.6779346\tbest: 0.6781317 (1476)\ttotal: 9m 41s\tremaining: 22m 36s\n",
      "1600:\tlearn: 0.6663127\ttest: 0.6781239\tbest: 0.6783100 (1537)\ttotal: 10m 21s\tremaining: 21m 59s\n",
      "1700:\tlearn: 0.6667596\ttest: 0.6785383\tbest: 0.6786438 (1645)\ttotal: 11m\tremaining: 21m 21s\n",
      "1800:\tlearn: 0.6671420\ttest: 0.6785977\tbest: 0.6786438 (1645)\ttotal: 11m 40s\tremaining: 20m 44s\n",
      "1900:\tlearn: 0.6675154\ttest: 0.6790334\tbest: 0.6791249 (1888)\ttotal: 12m 18s\tremaining: 20m 3s\n",
      "2000:\tlearn: 0.6678548\ttest: 0.6793395\tbest: 0.6793472 (1989)\ttotal: 12m 55s\tremaining: 19m 22s\n",
      "2100:\tlearn: 0.6682944\ttest: 0.6797942\tbest: 0.6797963 (2064)\ttotal: 13m 35s\tremaining: 18m 45s\n",
      "2200:\tlearn: 0.6685802\ttest: 0.6798184\tbest: 0.6799462 (2189)\ttotal: 14m 14s\tremaining: 18m 6s\n",
      "2300:\tlearn: 0.6690304\ttest: 0.6799432\tbest: 0.6800620 (2288)\ttotal: 14m 52s\tremaining: 17m 27s\n",
      "2400:\tlearn: 0.6692748\ttest: 0.6800068\tbest: 0.6800863 (2364)\ttotal: 15m 31s\tremaining: 16m 48s\n",
      "2500:\tlearn: 0.6694086\ttest: 0.6804615\tbest: 0.6805174 (2497)\ttotal: 16m 10s\tremaining: 16m 9s\n",
      "2600:\tlearn: 0.6697353\ttest: 0.6804923\tbest: 0.6805956 (2507)\ttotal: 16m 48s\tremaining: 15m 30s\n",
      "2700:\tlearn: 0.6700585\ttest: 0.6806147\tbest: 0.6806938 (2666)\ttotal: 17m 28s\tremaining: 14m 52s\n",
      "2800:\tlearn: 0.6702379\ttest: 0.6806747\tbest: 0.6807611 (2720)\ttotal: 18m 6s\tremaining: 14m 12s\n",
      "2900:\tlearn: 0.6706865\ttest: 0.6808679\tbest: 0.6810847 (2881)\ttotal: 18m 46s\tremaining: 13m 34s\n",
      "3000:\tlearn: 0.6707050\ttest: 0.6810588\tbest: 0.6812224 (2985)\ttotal: 19m 25s\tremaining: 12m 56s\n",
      "3100:\tlearn: 0.6710563\ttest: 0.6811611\tbest: 0.6812224 (2985)\ttotal: 20m 4s\tremaining: 12m 17s\n",
      "3200:\tlearn: 0.6712700\ttest: 0.6813706\tbest: 0.6814206 (3197)\ttotal: 20m 43s\tremaining: 11m 38s\n",
      "3300:\tlearn: 0.6714347\ttest: 0.6816192\tbest: 0.6816207 (3268)\ttotal: 21m 21s\tremaining: 10m 59s\n",
      "3400:\tlearn: 0.6715030\ttest: 0.6817857\tbest: 0.6818060 (3397)\ttotal: 22m\tremaining: 10m 20s\n",
      "3500:\tlearn: 0.6718792\ttest: 0.6818201\tbest: 0.6820254 (3464)\ttotal: 22m 40s\tremaining: 9m 42s\n",
      "3600:\tlearn: 0.6720509\ttest: 0.6821015\tbest: 0.6822228 (3529)\ttotal: 23m 19s\tremaining: 9m 3s\n",
      "3700:\tlearn: 0.6721744\ttest: 0.6821399\tbest: 0.6822228 (3529)\ttotal: 23m 56s\tremaining: 8m 24s\n",
      "3800:\tlearn: 0.6723085\ttest: 0.6821856\tbest: 0.6822773 (3799)\ttotal: 24m 35s\tremaining: 7m 45s\n",
      "3900:\tlearn: 0.6724551\ttest: 0.6824238\tbest: 0.6824994 (3873)\ttotal: 25m 14s\tremaining: 7m 6s\n",
      "4000:\tlearn: 0.6725840\ttest: 0.6826388\tbest: 0.6826810 (3990)\ttotal: 25m 54s\tremaining: 6m 28s\n",
      "4100:\tlearn: 0.6728052\ttest: 0.6827946\tbest: 0.6828987 (4095)\ttotal: 26m 32s\tremaining: 5m 49s\n",
      "4200:\tlearn: 0.6726980\ttest: 0.6827711\tbest: 0.6829477 (4135)\ttotal: 27m 10s\tremaining: 5m 10s\n",
      "4300:\tlearn: 0.6728761\ttest: 0.6829560\tbest: 0.6829560 (4300)\ttotal: 27m 50s\tremaining: 4m 31s\n",
      "4400:\tlearn: 0.6730042\ttest: 0.6829773\tbest: 0.6830055 (4347)\ttotal: 28m 30s\tremaining: 3m 52s\n",
      "4500:\tlearn: 0.6730747\ttest: 0.6829409\tbest: 0.6832033 (4447)\ttotal: 29m 8s\tremaining: 3m 13s\n",
      "4600:\tlearn: 0.6732821\ttest: 0.6829362\tbest: 0.6832033 (4447)\ttotal: 29m 47s\tremaining: 2m 35s\n",
      "4700:\tlearn: 0.6734051\ttest: 0.6833024\tbest: 0.6833362 (4685)\ttotal: 30m 26s\tremaining: 1m 56s\n",
      "4800:\tlearn: 0.6735653\ttest: 0.6832325\tbest: 0.6834143 (4705)\ttotal: 31m 3s\tremaining: 1m 17s\n",
      "4900:\tlearn: 0.6737446\ttest: 0.6834651\tbest: 0.6836635 (4869)\ttotal: 31m 42s\tremaining: 38.4s\n",
      "4999:\tlearn: 0.6738906\ttest: 0.6838359\tbest: 0.6838915 (4980)\ttotal: 32m 21s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.6838914858\n",
      "bestIteration = 4980\n",
      "\n",
      "Shrink model to first 4981 iterations.\n",
      "0:\tlearn: 0.6494678\ttest: 0.6488280\tbest: 0.6488280 (0)\ttotal: 519ms\tremaining: 43m 14s\n",
      "100:\tlearn: 0.6360589\ttest: 0.6413287\tbest: 0.6488280 (0)\ttotal: 36.1s\tremaining: 29m 11s\n",
      "200:\tlearn: 0.6460020\ttest: 0.6523164\tbest: 0.6524054 (199)\ttotal: 1m 16s\tremaining: 30m 20s\n",
      "300:\tlearn: 0.6515984\ttest: 0.6588045\tbest: 0.6588045 (300)\ttotal: 1m 56s\tremaining: 30m 14s\n",
      "400:\tlearn: 0.6556324\ttest: 0.6639142\tbest: 0.6639142 (400)\ttotal: 2m 35s\tremaining: 29m 38s\n",
      "500:\tlearn: 0.6581774\ttest: 0.6679933\tbest: 0.6679933 (500)\ttotal: 3m 16s\tremaining: 29m 20s\n",
      "600:\tlearn: 0.6599664\ttest: 0.6699974\tbest: 0.6702807 (599)\ttotal: 3m 54s\tremaining: 28m 37s\n",
      "700:\tlearn: 0.6613473\ttest: 0.6712079\tbest: 0.6713138 (698)\ttotal: 4m 33s\tremaining: 27m 57s\n",
      "800:\tlearn: 0.6623787\ttest: 0.6724178\tbest: 0.6724178 (800)\ttotal: 5m 12s\tremaining: 27m 16s\n",
      "900:\tlearn: 0.6636579\ttest: 0.6737203\tbest: 0.6737203 (900)\ttotal: 5m 52s\tremaining: 26m 45s\n",
      "1000:\tlearn: 0.6644856\ttest: 0.6749734\tbest: 0.6749734 (1000)\ttotal: 6m 32s\tremaining: 26m 9s\n",
      "1100:\tlearn: 0.6656195\ttest: 0.6758694\tbest: 0.6758694 (1100)\ttotal: 7m 15s\tremaining: 25m 42s\n",
      "1200:\tlearn: 0.6662677\ttest: 0.6763083\tbest: 0.6763083 (1200)\ttotal: 7m 54s\tremaining: 25m 1s\n",
      "1300:\tlearn: 0.6669053\ttest: 0.6763950\tbest: 0.6765051 (1282)\ttotal: 8m 34s\tremaining: 24m 21s\n",
      "1400:\tlearn: 0.6672704\ttest: 0.6769614\tbest: 0.6771655 (1379)\ttotal: 9m 14s\tremaining: 23m 44s\n",
      "1500:\tlearn: 0.6679845\ttest: 0.6773036\tbest: 0.6773036 (1500)\ttotal: 9m 53s\tremaining: 23m 2s\n",
      "1600:\tlearn: 0.6683906\ttest: 0.6777124\tbest: 0.6777632 (1588)\ttotal: 10m 30s\tremaining: 22m 19s\n",
      "1700:\tlearn: 0.6687501\ttest: 0.6780925\tbest: 0.6781120 (1687)\ttotal: 11m 9s\tremaining: 21m 38s\n",
      "1800:\tlearn: 0.6690813\ttest: 0.6780239\tbest: 0.6782679 (1735)\ttotal: 11m 48s\tremaining: 20m 57s\n",
      "1900:\tlearn: 0.6693302\ttest: 0.6780991\tbest: 0.6783226 (1882)\ttotal: 12m 27s\tremaining: 20m 18s\n",
      "2000:\tlearn: 0.6696385\ttest: 0.6781688\tbest: 0.6783226 (1882)\ttotal: 13m 6s\tremaining: 19m 39s\n",
      "2100:\tlearn: 0.6699892\ttest: 0.6786110\tbest: 0.6786110 (2100)\ttotal: 13m 46s\tremaining: 19m\n",
      "2200:\tlearn: 0.6701725\ttest: 0.6786609\tbest: 0.6788848 (2175)\ttotal: 14m 26s\tremaining: 18m 21s\n",
      "2300:\tlearn: 0.6704887\ttest: 0.6791049\tbest: 0.6791475 (2298)\ttotal: 15m 5s\tremaining: 17m 42s\n",
      "2400:\tlearn: 0.6708396\ttest: 0.6792171\tbest: 0.6794556 (2354)\ttotal: 15m 44s\tremaining: 17m 2s\n",
      "2500:\tlearn: 0.6711262\ttest: 0.6796274\tbest: 0.6796491 (2489)\ttotal: 16m 22s\tremaining: 16m 21s\n",
      "2600:\tlearn: 0.6713370\ttest: 0.6795518\tbest: 0.6797404 (2559)\ttotal: 17m 1s\tremaining: 15m 42s\n",
      "2700:\tlearn: 0.6715433\ttest: 0.6794778\tbest: 0.6797404 (2559)\ttotal: 17m 40s\tremaining: 15m 2s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.6797403732\n",
      "bestIteration = 2559\n",
      "\n",
      "Shrink model to first 2560 iterations.\n",
      "0:\tlearn: 0.6487452\ttest: 0.6479843\tbest: 0.6479843 (0)\ttotal: 574ms\tremaining: 47m 47s\n",
      "100:\tlearn: 0.6335195\ttest: 0.6377466\tbest: 0.6479904 (1)\ttotal: 36.8s\tremaining: 29m 45s\n",
      "200:\tlearn: 0.6445878\ttest: 0.6525571\tbest: 0.6525571 (200)\ttotal: 1m 17s\tremaining: 30m 53s\n",
      "300:\tlearn: 0.6508902\ttest: 0.6593388\tbest: 0.6593388 (300)\ttotal: 1m 56s\tremaining: 30m 19s\n",
      "400:\tlearn: 0.6545255\ttest: 0.6647338\tbest: 0.6647486 (391)\ttotal: 2m 36s\tremaining: 29m 53s\n",
      "500:\tlearn: 0.6568507\ttest: 0.6682718\tbest: 0.6682718 (500)\ttotal: 3m 15s\tremaining: 29m 18s\n",
      "600:\tlearn: 0.6588909\ttest: 0.6709423\tbest: 0.6709813 (577)\ttotal: 3m 56s\tremaining: 28m 49s\n",
      "700:\tlearn: 0.6606735\ttest: 0.6728751\tbest: 0.6730234 (697)\ttotal: 4m 36s\tremaining: 28m 16s\n",
      "800:\tlearn: 0.6619061\ttest: 0.6735442\tbest: 0.6737676 (781)\ttotal: 5m 16s\tremaining: 27m 41s\n",
      "900:\tlearn: 0.6630377\ttest: 0.6750762\tbest: 0.6751036 (898)\ttotal: 5m 56s\tremaining: 27m 2s\n",
      "1000:\tlearn: 0.6637909\ttest: 0.6760962\tbest: 0.6760962 (1000)\ttotal: 6m 37s\tremaining: 26m 29s\n",
      "1100:\tlearn: 0.6645420\ttest: 0.6764825\tbest: 0.6765603 (1097)\ttotal: 7m 17s\tremaining: 25m 49s\n",
      "1200:\tlearn: 0.6653076\ttest: 0.6770431\tbest: 0.6771165 (1172)\ttotal: 7m 57s\tremaining: 25m 10s\n",
      "1300:\tlearn: 0.6656696\ttest: 0.6778520\tbest: 0.6778520 (1300)\ttotal: 8m 36s\tremaining: 24m 28s\n",
      "1400:\tlearn: 0.6661850\ttest: 0.6782103\tbest: 0.6782103 (1400)\ttotal: 9m 16s\tremaining: 23m 50s\n",
      "1500:\tlearn: 0.6665168\ttest: 0.6787203\tbest: 0.6787739 (1474)\ttotal: 9m 57s\tremaining: 23m 12s\n",
      "1600:\tlearn: 0.6667755\ttest: 0.6794480\tbest: 0.6794528 (1587)\ttotal: 10m 38s\tremaining: 22m 35s\n",
      "1700:\tlearn: 0.6670680\ttest: 0.6798153\tbest: 0.6798239 (1680)\ttotal: 11m 18s\tremaining: 21m 56s\n",
      "1800:\tlearn: 0.6675263\ttest: 0.6802708\tbest: 0.6802708 (1800)\ttotal: 11m 59s\tremaining: 21m 18s\n",
      "1900:\tlearn: 0.6678811\ttest: 0.6806048\tbest: 0.6806048 (1900)\ttotal: 12m 38s\tremaining: 20m 35s\n",
      "2000:\tlearn: 0.6683820\ttest: 0.6807269\tbest: 0.6807826 (1988)\ttotal: 13m 17s\tremaining: 19m 55s\n",
      "2100:\tlearn: 0.6687651\ttest: 0.6811253\tbest: 0.6811897 (2093)\ttotal: 13m 56s\tremaining: 19m 14s\n",
      "2200:\tlearn: 0.6690110\ttest: 0.6813915\tbest: 0.6815243 (2175)\ttotal: 14m 37s\tremaining: 18m 35s\n",
      "2300:\tlearn: 0.6694226\ttest: 0.6817959\tbest: 0.6818269 (2274)\ttotal: 15m 18s\tremaining: 17m 56s\n",
      "2400:\tlearn: 0.6699992\ttest: 0.6820311\tbest: 0.6822410 (2369)\ttotal: 15m 58s\tremaining: 17m 17s\n",
      "2500:\tlearn: 0.6702344\ttest: 0.6822575\tbest: 0.6823199 (2486)\ttotal: 16m 39s\tremaining: 16m 38s\n",
      "2600:\tlearn: 0.6703913\ttest: 0.6823940\tbest: 0.6824506 (2598)\ttotal: 17m 18s\tremaining: 15m 57s\n",
      "2700:\tlearn: 0.6707687\ttest: 0.6823176\tbest: 0.6824506 (2598)\ttotal: 17m 58s\tremaining: 15m 18s\n",
      "2800:\tlearn: 0.6709521\ttest: 0.6824489\tbest: 0.6825752 (2759)\ttotal: 18m 39s\tremaining: 14m 39s\n",
      "2900:\tlearn: 0.6711099\ttest: 0.6826925\tbest: 0.6827694 (2897)\ttotal: 19m 20s\tremaining: 13m 59s\n",
      "3000:\tlearn: 0.6714251\ttest: 0.6828089\tbest: 0.6828593 (2971)\ttotal: 20m 2s\tremaining: 13m 21s\n",
      "3100:\tlearn: 0.6717281\ttest: 0.6829112\tbest: 0.6830323 (3071)\ttotal: 20m 43s\tremaining: 12m 41s\n",
      "3200:\tlearn: 0.6718725\ttest: 0.6831254\tbest: 0.6831254 (3200)\ttotal: 21m 22s\tremaining: 12m\n",
      "3300:\tlearn: 0.6720072\ttest: 0.6832490\tbest: 0.6833534 (3238)\ttotal: 22m 1s\tremaining: 11m 19s\n",
      "3400:\tlearn: 0.6721979\ttest: 0.6835753\tbest: 0.6836797 (3395)\ttotal: 22m 39s\tremaining: 10m 38s\n",
      "3500:\tlearn: 0.6724059\ttest: 0.6838388\tbest: 0.6838579 (3432)\ttotal: 23m 18s\tremaining: 9m 58s\n",
      "3600:\tlearn: 0.6725251\ttest: 0.6838159\tbest: 0.6839016 (3511)\ttotal: 23m 56s\tremaining: 9m 17s\n",
      "3700:\tlearn: 0.6727352\ttest: 0.6839162\tbest: 0.6839162 (3699)\ttotal: 24m 34s\tremaining: 8m 37s\n",
      "3800:\tlearn: 0.6729533\ttest: 0.6837916\tbest: 0.6839393 (3740)\ttotal: 25m 13s\tremaining: 7m 57s\n",
      "3900:\tlearn: 0.6730066\ttest: 0.6837080\tbest: 0.6839393 (3740)\ttotal: 25m 51s\tremaining: 7m 17s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.6839392584\n",
      "bestIteration = 3740\n",
      "\n",
      "Shrink model to first 3741 iterations.\n",
      "0:\tlearn: 0.6472364\ttest: 0.6482936\tbest: 0.6482936 (0)\ttotal: 417ms\tremaining: 34m 44s\n",
      "100:\tlearn: 0.6321697\ttest: 0.6427424\tbest: 0.6483063 (2)\ttotal: 39.5s\tremaining: 31m 55s\n",
      "200:\tlearn: 0.6438878\ttest: 0.6570686\tbest: 0.6570686 (200)\ttotal: 1m 23s\tremaining: 33m 8s\n",
      "300:\tlearn: 0.6494482\ttest: 0.6643269\tbest: 0.6643269 (300)\ttotal: 2m 5s\tremaining: 32m 41s\n",
      "400:\tlearn: 0.6533810\ttest: 0.6691012\tbest: 0.6692205 (397)\ttotal: 2m 48s\tremaining: 32m 15s\n",
      "500:\tlearn: 0.6560061\ttest: 0.6721774\tbest: 0.6722127 (497)\ttotal: 3m 29s\tremaining: 31m 18s\n",
      "600:\tlearn: 0.6579273\ttest: 0.6745126\tbest: 0.6745126 (600)\ttotal: 4m 8s\tremaining: 30m 19s\n",
      "700:\tlearn: 0.6596505\ttest: 0.6763906\tbest: 0.6765890 (693)\ttotal: 4m 49s\tremaining: 29m 33s\n",
      "800:\tlearn: 0.6608117\ttest: 0.6771667\tbest: 0.6775674 (785)\ttotal: 5m 27s\tremaining: 28m 35s\n",
      "900:\tlearn: 0.6618965\ttest: 0.6787771\tbest: 0.6787771 (900)\ttotal: 6m 7s\tremaining: 27m 53s\n",
      "1000:\tlearn: 0.6625480\ttest: 0.6792844\tbest: 0.6793123 (998)\ttotal: 6m 49s\tremaining: 27m 14s\n",
      "1100:\tlearn: 0.6633954\ttest: 0.6796389\tbest: 0.6799121 (1070)\ttotal: 7m 27s\tremaining: 26m 25s\n",
      "1200:\tlearn: 0.6638143\ttest: 0.6798110\tbest: 0.6800114 (1180)\ttotal: 8m 7s\tremaining: 25m 42s\n",
      "1300:\tlearn: 0.6644756\ttest: 0.6803494\tbest: 0.6804657 (1252)\ttotal: 8m 47s\tremaining: 25m\n",
      "1400:\tlearn: 0.6651237\ttest: 0.6810697\tbest: 0.6810797 (1368)\ttotal: 9m 27s\tremaining: 24m 16s\n",
      "1500:\tlearn: 0.6655174\ttest: 0.6818557\tbest: 0.6819816 (1498)\ttotal: 10m 6s\tremaining: 23m 33s\n",
      "1600:\tlearn: 0.6661611\ttest: 0.6822666\tbest: 0.6823430 (1592)\ttotal: 10m 46s\tremaining: 22m 52s\n",
      "1700:\tlearn: 0.6665023\ttest: 0.6822609\tbest: 0.6823843 (1628)\ttotal: 11m 27s\tremaining: 22m 12s\n",
      "1800:\tlearn: 0.6669846\ttest: 0.6823913\tbest: 0.6826105 (1735)\ttotal: 12m 6s\tremaining: 21m 30s\n",
      "1900:\tlearn: 0.6673704\ttest: 0.6826117\tbest: 0.6827829 (1876)\ttotal: 12m 45s\tremaining: 20m 48s\n",
      "2000:\tlearn: 0.6678701\ttest: 0.6828370\tbest: 0.6829655 (1960)\ttotal: 13m 24s\tremaining: 20m 5s\n",
      "2100:\tlearn: 0.6683305\ttest: 0.6830646\tbest: 0.6833374 (2076)\ttotal: 14m 4s\tremaining: 19m 24s\n",
      "2200:\tlearn: 0.6687000\ttest: 0.6832091\tbest: 0.6833705 (2164)\ttotal: 14m 45s\tremaining: 18m 45s\n",
      "2300:\tlearn: 0.6689127\ttest: 0.6833421\tbest: 0.6834988 (2277)\ttotal: 15m 23s\tremaining: 18m 3s\n",
      "2400:\tlearn: 0.6690305\ttest: 0.6836311\tbest: 0.6836311 (2400)\ttotal: 16m 2s\tremaining: 17m 21s\n",
      "2500:\tlearn: 0.6694638\ttest: 0.6838626\tbest: 0.6839406 (2487)\ttotal: 16m 41s\tremaining: 16m 40s\n",
      "2600:\tlearn: 0.6694480\ttest: 0.6839422\tbest: 0.6841170 (2540)\ttotal: 17m 20s\tremaining: 15m 59s\n",
      "2700:\tlearn: 0.6696569\ttest: 0.6841265\tbest: 0.6841961 (2654)\ttotal: 18m 5s\tremaining: 15m 23s\n",
      "2800:\tlearn: 0.6700337\ttest: 0.6844460\tbest: 0.6844956 (2793)\ttotal: 18m 54s\tremaining: 14m 50s\n",
      "2900:\tlearn: 0.6702389\ttest: 0.6850155\tbest: 0.6851341 (2884)\ttotal: 19m 40s\tremaining: 14m 13s\n",
      "3000:\tlearn: 0.6705027\ttest: 0.6846578\tbest: 0.6851341 (2884)\ttotal: 20m 27s\tremaining: 13m 37s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.6851340631\n",
      "bestIteration = 2884\n",
      "\n",
      "Shrink model to first 2885 iterations.\n",
      "0:\tlearn: 0.6495764\ttest: 0.6485476\tbest: 0.6485476 (0)\ttotal: 488ms\tremaining: 40m 37s\n",
      "100:\tlearn: 0.6318493\ttest: 0.6423264\tbest: 0.6485476 (0)\ttotal: 46.7s\tremaining: 37m 45s\n",
      "200:\tlearn: 0.6430918\ttest: 0.6544818\tbest: 0.6544818 (200)\ttotal: 1m 37s\tremaining: 38m 55s\n",
      "300:\tlearn: 0.6487184\ttest: 0.6610476\tbest: 0.6613255 (299)\ttotal: 2m 23s\tremaining: 37m 15s\n",
      "400:\tlearn: 0.6533605\ttest: 0.6670137\tbest: 0.6670137 (400)\ttotal: 3m 11s\tremaining: 36m 30s\n",
      "500:\tlearn: 0.6558446\ttest: 0.6699658\tbest: 0.6700786 (498)\ttotal: 3m 56s\tremaining: 35m 21s\n",
      "600:\tlearn: 0.6583635\ttest: 0.6728771\tbest: 0.6728771 (600)\ttotal: 4m 40s\tremaining: 34m 16s\n",
      "700:\tlearn: 0.6604064\ttest: 0.6746115\tbest: 0.6747103 (698)\ttotal: 5m 26s\tremaining: 33m 24s\n",
      "800:\tlearn: 0.6614975\ttest: 0.6761581\tbest: 0.6761581 (800)\ttotal: 6m 13s\tremaining: 32m 37s\n",
      "900:\tlearn: 0.6627276\ttest: 0.6764221\tbest: 0.6766408 (895)\ttotal: 6m 58s\tremaining: 31m 43s\n",
      "1000:\tlearn: 0.6637078\ttest: 0.6775497\tbest: 0.6776269 (998)\ttotal: 7m 49s\tremaining: 31m 17s\n",
      "1100:\tlearn: 0.6647363\ttest: 0.6783197\tbest: 0.6784701 (1068)\ttotal: 8m 32s\tremaining: 30m 14s\n",
      "1200:\tlearn: 0.6653568\ttest: 0.6786535\tbest: 0.6787515 (1199)\ttotal: 9m 16s\tremaining: 29m 19s\n",
      "1300:\tlearn: 0.6659093\ttest: 0.6790955\tbest: 0.6790996 (1282)\ttotal: 9m 58s\tremaining: 28m 20s\n",
      "1400:\tlearn: 0.6667220\ttest: 0.6797630\tbest: 0.6797949 (1398)\ttotal: 10m 43s\tremaining: 27m 33s\n",
      "1500:\tlearn: 0.6673253\ttest: 0.6801833\tbest: 0.6802190 (1495)\ttotal: 11m 25s\tremaining: 26m 38s\n",
      "1600:\tlearn: 0.6677946\ttest: 0.6803488\tbest: 0.6805217 (1513)\ttotal: 12m 7s\tremaining: 25m 45s\n",
      "1700:\tlearn: 0.6683712\ttest: 0.6808257\tbest: 0.6809320 (1694)\ttotal: 12m 54s\tremaining: 25m 1s\n",
      "1800:\tlearn: 0.6687478\ttest: 0.6808511\tbest: 0.6811189 (1787)\ttotal: 13m 38s\tremaining: 24m 13s\n",
      "1900:\tlearn: 0.6690512\ttest: 0.6813395\tbest: 0.6814000 (1885)\ttotal: 14m 18s\tremaining: 23m 19s\n",
      "2000:\tlearn: 0.6694564\ttest: 0.6817234\tbest: 0.6818298 (1998)\ttotal: 14m 58s\tremaining: 22m 27s\n",
      "2100:\tlearn: 0.6697270\ttest: 0.6823201\tbest: 0.6824776 (2082)\ttotal: 15m 37s\tremaining: 21m 33s\n",
      "2200:\tlearn: 0.6699802\ttest: 0.6825615\tbest: 0.6826196 (2190)\ttotal: 16m 18s\tremaining: 20m 43s\n",
      "2300:\tlearn: 0.6702636\ttest: 0.6825382\tbest: 0.6829123 (2228)\ttotal: 16m 58s\tremaining: 19m 55s\n",
      "2400:\tlearn: 0.6704589\ttest: 0.6829813\tbest: 0.6830353 (2363)\ttotal: 17m 39s\tremaining: 19m 6s\n",
      "2500:\tlearn: 0.6707560\ttest: 0.6829107\tbest: 0.6830758 (2456)\ttotal: 18m 19s\tremaining: 18m 18s\n",
      "2600:\tlearn: 0.6711051\ttest: 0.6828557\tbest: 0.6830758 (2456)\ttotal: 19m\tremaining: 17m 32s\n",
      "2700:\tlearn: 0.6713165\ttest: 0.6829715\tbest: 0.6831138 (2689)\ttotal: 19m 40s\tremaining: 16m 44s\n",
      "2800:\tlearn: 0.6714148\ttest: 0.6832037\tbest: 0.6833497 (2755)\ttotal: 20m 20s\tremaining: 15m 57s\n",
      "2900:\tlearn: 0.6716077\ttest: 0.6836675\tbest: 0.6836697 (2888)\ttotal: 20m 59s\tremaining: 15m 11s\n",
      "3000:\tlearn: 0.6716750\ttest: 0.6835804\tbest: 0.6837257 (2911)\ttotal: 21m 39s\tremaining: 14m 25s\n",
      "3100:\tlearn: 0.6719884\ttest: 0.6835187\tbest: 0.6837257 (2911)\ttotal: 22m 19s\tremaining: 13m 40s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.6837257345\n",
      "bestIteration = 2911\n",
      "\n",
      "Shrink model to first 2912 iterations.\n",
      "0:\tlearn: 0.6494242\ttest: 0.6489795\tbest: 0.6489795 (0)\ttotal: 438ms\tremaining: 36m 32s\n",
      "100:\tlearn: 0.6352899\ttest: 0.6450128\tbest: 0.6489795 (0)\ttotal: 39.6s\tremaining: 32m 2s\n",
      "200:\tlearn: 0.6449326\ttest: 0.6561619\tbest: 0.6561619 (200)\ttotal: 1m 21s\tremaining: 32m 32s\n",
      "300:\tlearn: 0.6500807\ttest: 0.6615876\tbest: 0.6615876 (300)\ttotal: 2m 1s\tremaining: 31m 39s\n",
      "400:\tlearn: 0.6540107\ttest: 0.6667795\tbest: 0.6668358 (398)\ttotal: 2m 43s\tremaining: 31m 12s\n",
      "500:\tlearn: 0.6567099\ttest: 0.6707918\tbest: 0.6707918 (500)\ttotal: 3m 24s\tremaining: 30m 39s\n",
      "600:\tlearn: 0.6591750\ttest: 0.6729153\tbest: 0.6729783 (597)\ttotal: 4m 6s\tremaining: 30m\n",
      "700:\tlearn: 0.6608922\ttest: 0.6750069\tbest: 0.6750069 (700)\ttotal: 4m 47s\tremaining: 29m 22s\n",
      "800:\tlearn: 0.6620599\ttest: 0.6769610\tbest: 0.6769610 (800)\ttotal: 5m 29s\tremaining: 28m 48s\n",
      "900:\tlearn: 0.6629193\ttest: 0.6782209\tbest: 0.6782209 (900)\ttotal: 6m 8s\tremaining: 27m 55s\n",
      "1000:\tlearn: 0.6636799\ttest: 0.6789256\tbest: 0.6789531 (999)\ttotal: 6m 49s\tremaining: 27m 14s\n",
      "1100:\tlearn: 0.6645406\ttest: 0.6798569\tbest: 0.6799759 (1099)\ttotal: 7m 30s\tremaining: 26m 35s\n",
      "1200:\tlearn: 0.6651706\ttest: 0.6801836\tbest: 0.6803484 (1135)\ttotal: 8m 11s\tremaining: 25m 55s\n",
      "1300:\tlearn: 0.6656511\ttest: 0.6810499\tbest: 0.6811872 (1297)\ttotal: 8m 52s\tremaining: 25m 14s\n",
      "1400:\tlearn: 0.6661385\ttest: 0.6818729\tbest: 0.6818729 (1400)\ttotal: 9m 32s\tremaining: 24m 30s\n",
      "1500:\tlearn: 0.6667380\ttest: 0.6820379\tbest: 0.6821898 (1499)\ttotal: 10m 11s\tremaining: 23m 44s\n",
      "1600:\tlearn: 0.6671056\ttest: 0.6821972\tbest: 0.6822812 (1583)\ttotal: 10m 49s\tremaining: 22m 59s\n",
      "1700:\tlearn: 0.6673520\ttest: 0.6828140\tbest: 0.6828140 (1700)\ttotal: 11m 29s\tremaining: 22m 18s\n",
      "1800:\tlearn: 0.6678123\ttest: 0.6829315\tbest: 0.6830010 (1795)\ttotal: 12m 9s\tremaining: 21m 35s\n",
      "1900:\tlearn: 0.6680462\ttest: 0.6833923\tbest: 0.6833937 (1850)\ttotal: 12m 47s\tremaining: 20m 51s\n",
      "2000:\tlearn: 0.6684941\ttest: 0.6840354\tbest: 0.6841343 (1993)\ttotal: 13m 27s\tremaining: 20m 10s\n",
      "2100:\tlearn: 0.6688597\ttest: 0.6841349\tbest: 0.6844006 (2044)\ttotal: 14m 6s\tremaining: 19m 27s\n",
      "2200:\tlearn: 0.6690063\ttest: 0.6844691\tbest: 0.6844808 (2172)\ttotal: 14m 45s\tremaining: 18m 46s\n",
      "2300:\tlearn: 0.6693101\ttest: 0.6845564\tbest: 0.6847028 (2217)\ttotal: 15m 26s\tremaining: 18m 6s\n",
      "2400:\tlearn: 0.6696147\ttest: 0.6850502\tbest: 0.6851040 (2396)\ttotal: 16m 5s\tremaining: 17m 24s\n",
      "2500:\tlearn: 0.6698130\ttest: 0.6847053\tbest: 0.6851087 (2417)\ttotal: 16m 45s\tremaining: 16m 44s\n",
      "2600:\tlearn: 0.6699076\ttest: 0.6851044\tbest: 0.6851206 (2585)\ttotal: 17m 26s\tremaining: 16m 5s\n",
      "2700:\tlearn: 0.6701896\ttest: 0.6849741\tbest: 0.6853531 (2626)\ttotal: 18m 11s\tremaining: 15m 28s\n",
      "2800:\tlearn: 0.6703606\ttest: 0.6849228\tbest: 0.6853531 (2626)\ttotal: 18m 50s\tremaining: 14m 47s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.685353119\n",
      "bestIteration = 2626\n",
      "\n",
      "Shrink model to first 2627 iterations.\n",
      "0:\tlearn: 0.6491638\ttest: 0.6501874\tbest: 0.6501874 (0)\ttotal: 437ms\tremaining: 36m 23s\n",
      "100:\tlearn: 0.6321394\ttest: 0.6407807\tbest: 0.6501874 (0)\ttotal: 37.2s\tremaining: 30m 4s\n",
      "200:\tlearn: 0.6429168\ttest: 0.6547472\tbest: 0.6547472 (200)\ttotal: 1m 18s\tremaining: 31m 17s\n",
      "300:\tlearn: 0.6490493\ttest: 0.6615970\tbest: 0.6615970 (300)\ttotal: 1m 58s\tremaining: 30m 55s\n",
      "400:\tlearn: 0.6530813\ttest: 0.6650322\tbest: 0.6651103 (398)\ttotal: 2m 37s\tremaining: 30m 5s\n",
      "500:\tlearn: 0.6557304\ttest: 0.6688737\tbest: 0.6690500 (499)\ttotal: 3m 15s\tremaining: 29m 16s\n",
      "600:\tlearn: 0.6582856\ttest: 0.6704677\tbest: 0.6705375 (595)\ttotal: 3m 54s\tremaining: 28m 34s\n",
      "700:\tlearn: 0.6597623\ttest: 0.6726218\tbest: 0.6726218 (700)\ttotal: 4m 33s\tremaining: 27m 59s\n",
      "800:\tlearn: 0.6611790\ttest: 0.6739343\tbest: 0.6742158 (794)\ttotal: 5m 12s\tremaining: 27m 17s\n",
      "900:\tlearn: 0.6622744\ttest: 0.6748190\tbest: 0.6750043 (872)\ttotal: 5m 51s\tremaining: 26m 40s\n",
      "1000:\tlearn: 0.6630627\ttest: 0.6758404\tbest: 0.6760201 (989)\ttotal: 6m 32s\tremaining: 26m 7s\n",
      "1100:\tlearn: 0.6636286\ttest: 0.6767729\tbest: 0.6769492 (1087)\ttotal: 7m 14s\tremaining: 25m 37s\n",
      "1200:\tlearn: 0.6644912\ttest: 0.6777560\tbest: 0.6777968 (1195)\ttotal: 7m 54s\tremaining: 25m 1s\n",
      "1300:\tlearn: 0.6652126\ttest: 0.6788544\tbest: 0.6788613 (1295)\ttotal: 8m 34s\tremaining: 24m 22s\n",
      "1400:\tlearn: 0.6658744\ttest: 0.6790484\tbest: 0.6790958 (1396)\ttotal: 9m 14s\tremaining: 23m 44s\n",
      "1500:\tlearn: 0.6664092\ttest: 0.6797404\tbest: 0.6798662 (1498)\ttotal: 9m 54s\tremaining: 23m 4s\n",
      "1600:\tlearn: 0.6669652\ttest: 0.6799261\tbest: 0.6800161 (1599)\ttotal: 10m 34s\tremaining: 22m 27s\n",
      "1700:\tlearn: 0.6673800\ttest: 0.6803537\tbest: 0.6804825 (1689)\ttotal: 11m 15s\tremaining: 21m 49s\n",
      "1800:\tlearn: 0.6677750\ttest: 0.6803201\tbest: 0.6805105 (1722)\ttotal: 11m 54s\tremaining: 21m 9s\n",
      "1900:\tlearn: 0.6680538\ttest: 0.6805277\tbest: 0.6806620 (1889)\ttotal: 12m 34s\tremaining: 20m 30s\n",
      "2000:\tlearn: 0.6685432\ttest: 0.6811536\tbest: 0.6811536 (2000)\ttotal: 13m 14s\tremaining: 19m 50s\n",
      "2100:\tlearn: 0.6687983\ttest: 0.6813551\tbest: 0.6814667 (2084)\ttotal: 13m 53s\tremaining: 19m 10s\n",
      "2200:\tlearn: 0.6689823\ttest: 0.6812463\tbest: 0.6815034 (2111)\ttotal: 14m 32s\tremaining: 18m 29s\n",
      "2300:\tlearn: 0.6693052\ttest: 0.6816878\tbest: 0.6816878 (2300)\ttotal: 15m 11s\tremaining: 17m 48s\n",
      "2400:\tlearn: 0.6694659\ttest: 0.6817231\tbest: 0.6817858 (2349)\ttotal: 15m 50s\tremaining: 17m 8s\n",
      "2500:\tlearn: 0.6698174\ttest: 0.6815882\tbest: 0.6817858 (2349)\ttotal: 16m 30s\tremaining: 16m 29s\n",
      "2600:\tlearn: 0.6702070\ttest: 0.6819438\tbest: 0.6820085 (2587)\ttotal: 17m 9s\tremaining: 15m 49s\n",
      "2700:\tlearn: 0.6703879\ttest: 0.6820631\tbest: 0.6822664 (2684)\ttotal: 17m 49s\tremaining: 15m 10s\n",
      "2800:\tlearn: 0.6707201\ttest: 0.6824297\tbest: 0.6824732 (2794)\ttotal: 18m 29s\tremaining: 14m 30s\n",
      "2900:\tlearn: 0.6709822\ttest: 0.6823492\tbest: 0.6824732 (2794)\ttotal: 19m 8s\tremaining: 13m 50s\n",
      "3000:\tlearn: 0.6711177\ttest: 0.6824908\tbest: 0.6826770 (2977)\ttotal: 19m 49s\tremaining: 13m 12s\n",
      "3100:\tlearn: 0.6713343\ttest: 0.6826537\tbest: 0.6827102 (3097)\ttotal: 20m 30s\tremaining: 12m 33s\n",
      "3200:\tlearn: 0.6714717\ttest: 0.6825167\tbest: 0.6827102 (3097)\ttotal: 21m 10s\tremaining: 11m 53s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.682710186\n",
      "bestIteration = 3097\n",
      "\n",
      "Shrink model to first 3098 iterations.\n",
      "0:\tlearn: 0.6489845\ttest: 0.6508996\tbest: 0.6508996 (0)\ttotal: 379ms\tremaining: 31m 35s\n",
      "100:\tlearn: 0.6334267\ttest: 0.6441109\tbest: 0.6509049 (5)\ttotal: 38.6s\tremaining: 31m 12s\n",
      "200:\tlearn: 0.6441278\ttest: 0.6554098\tbest: 0.6555375 (197)\ttotal: 1m 23s\tremaining: 33m 15s\n",
      "300:\tlearn: 0.6495296\ttest: 0.6616110\tbest: 0.6616597 (293)\ttotal: 2m 8s\tremaining: 33m 29s\n",
      "400:\tlearn: 0.6537618\ttest: 0.6664685\tbest: 0.6665109 (399)\ttotal: 2m 50s\tremaining: 32m 39s\n",
      "500:\tlearn: 0.6562902\ttest: 0.6688847\tbest: 0.6689979 (491)\ttotal: 3m 30s\tremaining: 31m 33s\n",
      "600:\tlearn: 0.6587233\ttest: 0.6715211\tbest: 0.6715211 (600)\ttotal: 4m 12s\tremaining: 30m 46s\n",
      "700:\tlearn: 0.6602864\ttest: 0.6734655\tbest: 0.6734655 (700)\ttotal: 4m 53s\tremaining: 29m 57s\n",
      "800:\tlearn: 0.6615466\ttest: 0.6752944\tbest: 0.6753291 (799)\ttotal: 5m 35s\tremaining: 29m 20s\n",
      "900:\tlearn: 0.6626388\ttest: 0.6757021\tbest: 0.6760423 (865)\ttotal: 6m 17s\tremaining: 28m 37s\n",
      "1000:\tlearn: 0.6634352\ttest: 0.6760958\tbest: 0.6765174 (978)\ttotal: 6m 58s\tremaining: 27m 51s\n",
      "1100:\tlearn: 0.6643274\ttest: 0.6768437\tbest: 0.6768574 (1097)\ttotal: 7m 37s\tremaining: 27m 1s\n",
      "1200:\tlearn: 0.6649258\ttest: 0.6775744\tbest: 0.6776219 (1196)\ttotal: 8m 18s\tremaining: 26m 17s\n",
      "1300:\tlearn: 0.6654082\ttest: 0.6784369\tbest: 0.6784369 (1300)\ttotal: 8m 58s\tremaining: 25m 30s\n",
      "1400:\tlearn: 0.6660804\ttest: 0.6790343\tbest: 0.6790343 (1400)\ttotal: 9m 40s\tremaining: 24m 50s\n",
      "1500:\tlearn: 0.6666720\ttest: 0.6792461\tbest: 0.6793242 (1497)\ttotal: 10m 19s\tremaining: 24m 4s\n",
      "1600:\tlearn: 0.6670973\ttest: 0.6795954\tbest: 0.6798022 (1566)\ttotal: 10m 58s\tremaining: 23m 18s\n",
      "1700:\tlearn: 0.6673600\ttest: 0.6797698\tbest: 0.6800357 (1682)\ttotal: 11m 38s\tremaining: 22m 33s\n",
      "1800:\tlearn: 0.6678581\ttest: 0.6800531\tbest: 0.6801711 (1782)\ttotal: 12m 19s\tremaining: 21m 52s\n",
      "1900:\tlearn: 0.6680937\ttest: 0.6806207\tbest: 0.6807120 (1894)\ttotal: 12m 58s\tremaining: 21m 9s\n",
      "2000:\tlearn: 0.6684202\ttest: 0.6808018\tbest: 0.6808217 (1953)\ttotal: 13m 38s\tremaining: 20m 27s\n",
      "2100:\tlearn: 0.6686793\ttest: 0.6812646\tbest: 0.6812646 (2100)\ttotal: 14m 18s\tremaining: 19m 44s\n",
      "2200:\tlearn: 0.6691163\ttest: 0.6814480\tbest: 0.6815603 (2195)\ttotal: 14m 57s\tremaining: 19m\n",
      "2300:\tlearn: 0.6691879\ttest: 0.6818076\tbest: 0.6818577 (2280)\ttotal: 15m 37s\tremaining: 18m 19s\n",
      "2400:\tlearn: 0.6694056\ttest: 0.6818191\tbest: 0.6819054 (2306)\ttotal: 16m 17s\tremaining: 17m 38s\n",
      "2500:\tlearn: 0.6695651\ttest: 0.6818447\tbest: 0.6820676 (2446)\ttotal: 16m 58s\tremaining: 16m 57s\n",
      "2600:\tlearn: 0.6698312\ttest: 0.6818003\tbest: 0.6820676 (2446)\ttotal: 17m 36s\tremaining: 16m 14s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.6820675531\n",
      "bestIteration = 2446\n",
      "\n",
      "Shrink model to first 2447 iterations.\n"
     ]
    }
   ],
   "source": [
    "data1 = catboost_modeling(X_train, y_train, df_test, 'SymmetricTree', \n",
    "                          depth=3, learning_rate=4e-02, l2_leaf_reg=None, random_seed = 2022,n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "id": "XMNYB6_RabvF"
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv(SUBMIT_PATH + '/sample_submission.csv')\n",
    "submission['target'] = (data1> 0.3)*1\n",
    "\n",
    "submission.to_csv(SUBMIT_PATH + '/result.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.496253\n",
       "1        0.355875\n",
       "2        0.421571\n",
       "3        0.458768\n",
       "4        0.453540\n",
       "           ...   \n",
       "46399    0.534414\n",
       "46400    0.470199\n",
       "46401    0.572365\n",
       "46402    0.576690\n",
       "46403    0.589292\n",
       "Length: 46404, dtype: float64"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true,
    "id": "9zVmI7EvtOQ5"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "running_mean should contain 62 elements not 32",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-164-90574864bf4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 코드제출\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtabnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msubmission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSUBMIT_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/sample_submission.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msubmission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pytorch_tabnet/tab_model.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pytorch_tabnet/tab_network.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtabnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pytorch_tabnet/tab_network.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    466\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m         \u001b[0msteps_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pytorch_tabnet/tab_network.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, prior)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_bn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprior\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \"\"\"\n\u001b[0;32m--> 168\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    169\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2280\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2282\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   2283\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2284\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: running_mean should contain 62 elements not 32"
     ]
    }
   ],
   "source": [
    "\n",
    "# 코드제출\n",
    "\n",
    "preds = tabnet.predict_proba(df_test)\n",
    "\n",
    "submission = pd.read_csv(SUBMIT_PATH + '/sample_submission.csv')\n",
    "submission['target'] = (preds[:,1] > thres)*1\n",
    "\n",
    "submission.to_csv(SUBMIT_PATH + '/tabnet_thres=' + str(thres) +'_f1='+str(max(f1))+ '.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CATBOOST.ipynb",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "1I9KIbK_tVcpDUv252cnlG_ClfSSdo54Y",
     "timestamp": 1642221138419
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d89d9c2a8fda2769fa326fa3d00908c9a8759a8068a6e279faebea338bf14b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
